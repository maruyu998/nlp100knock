{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dealing with text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv('news_mod_1.csv',index_col=\"ID\")\n",
    "news['title'] = news['title'].apply(lambda title:title.split(','))\n",
    "news['uri'] = news['uri'].apply(lambda uri:uri.split(',') if type(uri) is str else [])\n",
    "news['uri_features'] = news['uri_features'].apply(lambda f:f if type(f) is str else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>genre</th>\n",
       "      <th>title</th>\n",
       "      <th>uri</th>\n",
       "      <th>story</th>\n",
       "      <th>uri_features</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>article</td>\n",
       "      <td>[Europe, reaches, crunch, point, on, banking, ...</td>\n",
       "      <td>[eu, banks, resoluton]</td>\n",
       "      <td>0</td>\n",
       "      <td>INL6N0M71NJ</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>article</td>\n",
       "      <td>[ECB, FOCUS-Stronger, euro, drowns, out, ECB's...</td>\n",
       "      <td>[ecb, policy]</td>\n",
       "      <td>0</td>\n",
       "      <td>INL6N0M71K3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>news</td>\n",
       "      <td>[Euro, Anxieties, Wane, as, Bunds, Top, Treasu...</td>\n",
       "      <td>[german, bonds, beat, treasuries, with, yield,...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>news</td>\n",
       "      <td>[Noyer, Says, Strong, Euro, Creates, Unwarrant...</td>\n",
       "      <td>[noyer, says, stronger, euro, creates, unwarra...</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>article</td>\n",
       "      <td>[REFILE-Bad, loan, triggers, key, feature, in,...</td>\n",
       "      <td>[eurozone, bank, tests]</td>\n",
       "      <td>0</td>\n",
       "      <td>INL6N0M71F0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0</td>\n",
       "      <td>8640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422819</th>\n",
       "      <td>m</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>hp</td>\n",
       "      <td>[UN, Ebola, Could, Eventually, Infect, 20000, ...</td>\n",
       "      <td>[ebola, 20000, people]</td>\n",
       "      <td>4577</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>254880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422820</th>\n",
       "      <td>m</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>article</td>\n",
       "      <td>[Ebola, toll, tops, 1550, continues, to, accel...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "      <td>4577</td>\n",
       "      <td>INL5N0QY2GR</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>254880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422821</th>\n",
       "      <td>m</td>\n",
       "      <td>Reuters</td>\n",
       "      <td>article</td>\n",
       "      <td>[UPDATE, 1-Ebola, toll, tops, 1550, outbreak, ...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "      <td>4577</td>\n",
       "      <td>INL5N0QY2J7</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>254880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422828</th>\n",
       "      <td>m</td>\n",
       "      <td>Businessweek</td>\n",
       "      <td>news</td>\n",
       "      <td>[Ebola, Cases, May, Surpass, 20000, WHO, Says,...</td>\n",
       "      <td>[ebola, cases, may, surpass, 20, 000, who, say...</td>\n",
       "      <td>4577</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>254880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422838</th>\n",
       "      <td>m</td>\n",
       "      <td>Daily Mail</td>\n",
       "      <td>travel-travel_news</td>\n",
       "      <td>[Air, France, suspends, flights, to, Ebola-hit...</td>\n",
       "      <td>[Citing, Ebola, Air, France, suspends, flights...</td>\n",
       "      <td>4577</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>Thu</td>\n",
       "      <td>2120</td>\n",
       "      <td>256160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13340 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CATEGORY        PUBLISHER               genre  \\\n",
       "ID                                                     \n",
       "13            b          Reuters             article   \n",
       "14            b          Reuters             article   \n",
       "20            b     Businessweek                news   \n",
       "21            b     Businessweek                news   \n",
       "30            b          Reuters             article   \n",
       "...         ...              ...                 ...   \n",
       "422819        m  Huffington Post                  hp   \n",
       "422820        m          Reuters             article   \n",
       "422821        m          Reuters             article   \n",
       "422828        m     Businessweek                news   \n",
       "422838        m       Daily Mail  travel-travel_news   \n",
       "\n",
       "                                                    title  \\\n",
       "ID                                                          \n",
       "13      [Europe, reaches, crunch, point, on, banking, ...   \n",
       "14      [ECB, FOCUS-Stronger, euro, drowns, out, ECB's...   \n",
       "20      [Euro, Anxieties, Wane, as, Bunds, Top, Treasu...   \n",
       "21      [Noyer, Says, Strong, Euro, Creates, Unwarrant...   \n",
       "30      [REFILE-Bad, loan, triggers, key, feature, in,...   \n",
       "...                                                   ...   \n",
       "422819  [UN, Ebola, Could, Eventually, Infect, 20000, ...   \n",
       "422820  [Ebola, toll, tops, 1550, continues, to, accel...   \n",
       "422821  [UPDATE, 1-Ebola, toll, tops, 1550, outbreak, ...   \n",
       "422828  [Ebola, Cases, May, Surpass, 20000, WHO, Says,...   \n",
       "422838  [Air, France, suspends, flights, to, Ebola-hit...   \n",
       "\n",
       "                                                      uri  story uri_features  \\\n",
       "ID                                                                              \n",
       "13                                 [eu, banks, resoluton]      0  INL6N0M71NJ   \n",
       "14                                          [ecb, policy]      0  INL6N0M71K3   \n",
       "20      [german, bonds, beat, treasuries, with, yield,...      0                \n",
       "21      [noyer, says, stronger, euro, creates, unwarra...      0                \n",
       "30                                [eurozone, bank, tests]      0  INL6N0M71F0   \n",
       "...                                                   ...    ...          ...   \n",
       "422819                             [ebola, 20000, people]   4577                \n",
       "422820                              [health, ebola, toll]   4577  INL5N0QY2GR   \n",
       "422821                              [health, ebola, toll]   4577  INL5N0QY2J7   \n",
       "422828  [ebola, cases, may, surpass, 20, 000, who, say...   4577                \n",
       "422838  [Citing, Ebola, Air, France, suspends, flights...   4577                \n",
       "\n",
       "        month  date  day  time        ts  \n",
       "ID                                        \n",
       "13          3    10  Mon     0    8640.0  \n",
       "14          3    10  Mon     0    8640.0  \n",
       "20          3    10  Mon     0    8640.0  \n",
       "21          3    10  Mon     0    8640.0  \n",
       "30          3    10  Mon     0    8640.0  \n",
       "...       ...   ...  ...   ...       ...  \n",
       "422819      8    28  Thu     0  254880.0  \n",
       "422820      8    28  Thu     0  254880.0  \n",
       "422821      8    28  Thu     0  254880.0  \n",
       "422828      8    28  Thu     0  254880.0  \n",
       "422838      8    28  Thu  2120  256160.0  \n",
       "\n",
       "[13340 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表記ゆれ・語幹を抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['uri_mod'] = news['uri']\n",
    "news['title_mod'] = news['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一度辞書を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(series,n):\n",
    "    dic = {}\n",
    "    for li in series:\n",
    "        for elm in li:\n",
    "            dic.setdefault(elm,0)\n",
    "            dic[elm] += 1\n",
    "    dic = {k:v for k,v in dic.items() if v>n}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回出現:31917種\n",
      "1回出現:17743種\n",
      "2回出現:12274種\n",
      "3回出現:9660種\n",
      "4回出現:7892種\n",
      "5回出現:6763種\n",
      "6回出現:5881種\n",
      "7回出現:5192種\n",
      "8回出現:4658種\n",
      "9回出現:4219種\n"
     ]
    }
   ],
   "source": [
    "print(*[\"{}回出現:{}種\".format(i,len(create_dic(news['uri_mod']+news['title_mod'],i))) for i in range(10)],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 末尾のsを取り除く"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_s = lambda li,keys: [e.rstrip('s') if len(e)>1 and e[-1]==\"s\" and e.rstrip('s') in keys else e for e in li]\n",
    "remove_S = lambda li,keys: [e.rstrip('S') if len(e)>1 and e[-1]==\"S\" and e.rstrip('S') in keys else e for e in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = create_dic(news['uri_mod']+news['title_mod'],0).keys()\n",
    "news['uri_mod'] = news['uri_mod'].apply(lambda li:remove_S(remove_s(li, keys),keys))\n",
    "news['title_mod'] = news['title_mod'].apply(lambda li:remove_S(remove_s(li, keys),keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回出現:28828種\n",
      "1回出現:16124種\n",
      "2回出現:11254種\n",
      "3回出現:8973種\n",
      "4回出現:7405種\n",
      "5回出現:6405種\n",
      "6回出現:5614種\n",
      "7回出現:4969種\n",
      "8回出現:4461種\n",
      "9回出現:4074種\n"
     ]
    }
   ],
   "source": [
    "print(*[\"{}回出現:{}種\".format(i,len(create_dic(news['uri_mod']+news['title_mod'],i))) for i in range(10)],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>uri</th>\n",
       "      <th>title_mod</th>\n",
       "      <th>uri_mod</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[Europe, reaches, crunch, point, on, banking, ...</td>\n",
       "      <td>[eu, banks, resoluton]</td>\n",
       "      <td>[europe, reaches, crunch, point, on, banking, ...</td>\n",
       "      <td>[eu, bank, resoluton]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[ECB, FOCUS-Stronger, euro, drowns, out, ECB's...</td>\n",
       "      <td>[ecb, policy]</td>\n",
       "      <td>[ECB, FOCUS-Stronger, euro, drowns, out, ECB's...</td>\n",
       "      <td>[ecb, policy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[Euro, Anxieties, Wane, as, Bunds, Top, Treasu...</td>\n",
       "      <td>[german, bonds, beat, treasuries, with, yield,...</td>\n",
       "      <td>[euro, anxieties, Wane, a, Bunds, top, treasur...</td>\n",
       "      <td>[german, bond, beat, treasuries, with, yield, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[Noyer, Says, Strong, Euro, Creates, Unwarrant...</td>\n",
       "      <td>[noyer, says, stronger, euro, creates, unwarra...</td>\n",
       "      <td>[noyer, say, strong, euro, create, unwarranted...</td>\n",
       "      <td>[noyer, say, stronger, euro, create, unwarrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[REFILE-Bad, loan, triggers, key, feature, in,...</td>\n",
       "      <td>[eurozone, bank, tests]</td>\n",
       "      <td>[REFILE-Bad, loan, trigger, key, feature, in, ...</td>\n",
       "      <td>[eurozone, bank, test]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422819</th>\n",
       "      <td>[UN, Ebola, Could, Eventually, Infect, 20000, ...</td>\n",
       "      <td>[ebola, 20000, people]</td>\n",
       "      <td>[UN, ebola, could, eventually, infect, 20000, ...</td>\n",
       "      <td>[ebola, 20000, people]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422820</th>\n",
       "      <td>[Ebola, toll, tops, 1550, continues, to, accel...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "      <td>[ebola, toll, top, 1550, continue, to, acceler...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422821</th>\n",
       "      <td>[UPDATE, 1-Ebola, toll, tops, 1550, outbreak, ...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "      <td>[UPDATE, 1-Ebola, toll, top, 1550, outbreak, a...</td>\n",
       "      <td>[health, ebola, toll]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422828</th>\n",
       "      <td>[Ebola, Cases, May, Surpass, 20000, WHO, Says,...</td>\n",
       "      <td>[ebola, cases, may, surpass, 20, 000, who, say...</td>\n",
       "      <td>[ebola, case, may, surpass, 20000, WHO, say, i...</td>\n",
       "      <td>[ebola, case, may, surpass, 20, 000, who, say,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422838</th>\n",
       "      <td>[Air, France, suspends, flights, to, Ebola-hit...</td>\n",
       "      <td>[Citing, Ebola, Air, France, suspends, flights...</td>\n",
       "      <td>[air, france, suspend, flight, to, Ebola-hit, ...</td>\n",
       "      <td>[citing, ebola, air, france, suspend, flights....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13340 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "ID                                                          \n",
       "13      [Europe, reaches, crunch, point, on, banking, ...   \n",
       "14      [ECB, FOCUS-Stronger, euro, drowns, out, ECB's...   \n",
       "20      [Euro, Anxieties, Wane, as, Bunds, Top, Treasu...   \n",
       "21      [Noyer, Says, Strong, Euro, Creates, Unwarrant...   \n",
       "30      [REFILE-Bad, loan, triggers, key, feature, in,...   \n",
       "...                                                   ...   \n",
       "422819  [UN, Ebola, Could, Eventually, Infect, 20000, ...   \n",
       "422820  [Ebola, toll, tops, 1550, continues, to, accel...   \n",
       "422821  [UPDATE, 1-Ebola, toll, tops, 1550, outbreak, ...   \n",
       "422828  [Ebola, Cases, May, Surpass, 20000, WHO, Says,...   \n",
       "422838  [Air, France, suspends, flights, to, Ebola-hit...   \n",
       "\n",
       "                                                      uri  \\\n",
       "ID                                                          \n",
       "13                                 [eu, banks, resoluton]   \n",
       "14                                          [ecb, policy]   \n",
       "20      [german, bonds, beat, treasuries, with, yield,...   \n",
       "21      [noyer, says, stronger, euro, creates, unwarra...   \n",
       "30                                [eurozone, bank, tests]   \n",
       "...                                                   ...   \n",
       "422819                             [ebola, 20000, people]   \n",
       "422820                              [health, ebola, toll]   \n",
       "422821                              [health, ebola, toll]   \n",
       "422828  [ebola, cases, may, surpass, 20, 000, who, say...   \n",
       "422838  [Citing, Ebola, Air, France, suspends, flights...   \n",
       "\n",
       "                                                title_mod  \\\n",
       "ID                                                          \n",
       "13      [europe, reaches, crunch, point, on, banking, ...   \n",
       "14      [ECB, FOCUS-Stronger, euro, drowns, out, ECB's...   \n",
       "20      [euro, anxieties, Wane, a, Bunds, top, treasur...   \n",
       "21      [noyer, say, strong, euro, create, unwarranted...   \n",
       "30      [REFILE-Bad, loan, trigger, key, feature, in, ...   \n",
       "...                                                   ...   \n",
       "422819  [UN, ebola, could, eventually, infect, 20000, ...   \n",
       "422820  [ebola, toll, top, 1550, continue, to, acceler...   \n",
       "422821  [UPDATE, 1-Ebola, toll, top, 1550, outbreak, a...   \n",
       "422828  [ebola, case, may, surpass, 20000, WHO, say, i...   \n",
       "422838  [air, france, suspend, flight, to, Ebola-hit, ...   \n",
       "\n",
       "                                                  uri_mod  \n",
       "ID                                                         \n",
       "13                                  [eu, bank, resoluton]  \n",
       "14                                          [ecb, policy]  \n",
       "20      [german, bond, beat, treasuries, with, yield, ...  \n",
       "21      [noyer, say, stronger, euro, create, unwarrant...  \n",
       "30                                 [eurozone, bank, test]  \n",
       "...                                                   ...  \n",
       "422819                             [ebola, 20000, people]  \n",
       "422820                              [health, ebola, toll]  \n",
       "422821                              [health, ebola, toll]  \n",
       "422828  [ebola, case, may, surpass, 20, 000, who, say,...  \n",
       "422838  [citing, ebola, air, france, suspend, flights....  \n",
       "\n",
       "[13340 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[['title','uri','title_mod','uri_mod']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 最初の文字だけ大文字のパターンは小文字に戻す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover = lambda li,keys: [word.lower() if len(word)>1 and 'A'<= word[0] <='Z' and sum(['A'<=c<='Z' for c in word[1:]]) == 0 and word.lower() in keys else word for word in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = create_dic(news['uri_mod']+news['title_mod'],0).keys()\n",
    "news['uri_mod'] = news['uri_mod'].apply(lambda li:recover(li, keys))\n",
    "news['title_mod'] = news['title_mod'].apply(lambda li:recover(li, keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回出現:21292種\n",
      "1回出現:12824種\n",
      "2回出現:8751種\n",
      "3回出現:7200種\n",
      "4回出現:6057種\n",
      "5回出現:5297種\n",
      "6回出現:4676種\n",
      "7回出現:4241種\n",
      "8回出現:3839種\n",
      "9回出現:3527種\n"
     ]
    }
   ],
   "source": [
    "print(*[\"{}回出現:{}種\".format(i,len(create_dic(news['uri_mod']+news['title_mod'],i))) for i in range(10)],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 全部大文字のパターンは全部小文字に戻す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover_2 = lambda li,keys: [word.lower() if sum([c<'A' or 'Z'<c for c in word]) == 0 and word.lower() in keys else word for word in li]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = create_dic(news['uri_mod']+news['title_mod'],0).keys()\n",
    "news['uri_mod'] = news['uri_mod'].apply(lambda li:recover_2(li, keys))\n",
    "news['title_mod'] = news['title_mod'].apply(lambda li:recover_2(li, keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0回出現:22581種\n",
      "1回出現:13843種\n",
      "2回出現:9463種\n",
      "3回出現:7747種\n",
      "4回出現:6504種\n",
      "5回出現:5682種\n",
      "6回出現:4997種\n",
      "7回出現:4544種\n",
      "8回出現:4130種\n",
      "9回出現:3796種\n"
     ]
    }
   ],
   "source": [
    "print(*[\"{}回出現:{}種\".format(i,len(create_dic(news['uri_mod']+news['title_mod'],i))) for i in range(10)],sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (title, uri)についてPPMIを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ppmi(series, keys=None):\n",
    "    dic = {}\n",
    "    for line in series:\n",
    "        for w1 in line:\n",
    "            if keys and w1 not in keys: continue\n",
    "            dic.setdefault(w1,{})\n",
    "            for w2 in line:\n",
    "                if keys and w2 not in keys: continue\n",
    "                if w1==w2: continue\n",
    "                dic[w1].setdefault(w2,0)\n",
    "                dic[w1][w2] += 1\n",
    "    counts = {w:sum(v.values()) for w,v in dic.items()}\n",
    "    s = sum(counts.values())\n",
    "    return lambda w1,w2,count=False: 0 if w1 not in dic.keys() or w2 not in dic[w1].keys() else dic[w1][w2] if count else math.log2(dic[w1][w2]*s/counts[w1]/counts[w2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ppmi = gen_ppmi(news['uri_mod']+news['title_mod'],create_dic(news['uri_mod']+news['title_mod'],2).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppmis(dic,n=None):\n",
    "    ppmi_dic = {}\n",
    "    for w1 in dic:\n",
    "        for w2 in dic:\n",
    "            if (w2,w1) in ppmi_dic.keys(): continue\n",
    "            if (o := ppmi(w1,w2)) > 0:\n",
    "                ppmi_dic[(w1,w2)] = o\n",
    "    if n is None: return ppmi_dic\n",
    "    return {k:v for k,v in sorted(ppmi_dic.items(), key=lambda x:x[1], reverse=True)[:n]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = ppmis(create_dic(news['uri_mod']+news['title_mod'],2).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('decarbonization', 'pathway'), 15.234705438418128),\n",
       " (('morningcall', 'Call-Global'), 14.7316279044262),\n",
       " (('ifr', 'regional'), 14.527487187645974),\n",
       " (('biogen', 'idec'), 14.509565279648712),\n",
       " (('nate', 'berku'), 14.357562186203662),\n",
       " (('jordana', 'brewster'), 14.296532752806103),\n",
       " (('barkhad', 'abdi'), 14.296532752806103),\n",
       " (('biogen', 'hemophilia'), 14.242084968783725),\n",
       " (('idec', 'hemophilia'), 14.242084968783725),\n",
       " (('subway', 'quizno'), 14.23798057045099),\n",
       " (('brominated', 'powerade'), 14.205559092758612),\n",
       " (('hercule', 'dwayne'), 14.090081875338676),\n",
       " (('silevo', 'SolarCity'), 14.068055569008678),\n",
       " (('loch', 'ne'), 14.053555999313563),\n",
       " (('cirru', 'wolfson'), 14.053555999313563),\n",
       " (('wally', 'pfister'), 14.01934028397565),\n",
       " (('arianna', 'huffington'), 13.994662310259994),\n",
       " (('sandisk', 'Fusion-io'), 13.994662310259994),\n",
       " (('vin', 'diesel'), 13.883630997871249),\n",
       " (('prdct', 'chem'), 13.772599685482506),\n",
       " (('cubist', 'anti-infective'), 13.72013226558837),\n",
       " (('dixon', 'carphone'), 13.70305875222943),\n",
       " (('solarcity', 'silevo'), 13.653018069729834),\n",
       " (('busby', 'berkeley'), 13.65028827697426),\n",
       " (('eliza', 'dushku'), 13.632565808505696),\n",
       " (('jewel', 'tolmach'), 13.620596592037456),\n",
       " (('teeth', 'wisdom'), 13.609949347837947),\n",
       " (('anemic', 'chug'), 13.60862395037138),\n",
       " ((\"Int'l\", 'raiffeisen'), 13.5732908772591),\n",
       " (('norway', 'tele2'), 13.534181840219983),\n",
       " (('romania', 'raiffeisen'), 13.468593498592407),\n",
       " (('danica', 'mckellar'), 13.37958849253366),\n",
       " (('nuri', 'bilge'), 13.375484094200925),\n",
       " (('whistleblower', 'retaliation'), 13.375484094200925),\n",
       " (('numericable', 'mid-term'), 13.357562186203662),\n",
       " (('celine', 'dion'), 13.357562186203662),\n",
       " (('gentiva', 'Kindred'), 13.357562186203662),\n",
       " (('solarcity', 'SolarCity'), 13.357562186203662),\n",
       " (('benelux', 'stocks-Factor'), 13.33108997484247),\n",
       " (('MOIR', 'sickly'), 13.305094766309526),\n",
       " (('nolan', 'futuristic'), 13.298668497150093),\n",
       " (('CORRECTED-GLOBAL', 'MARKETS-China'), 13.296532752806103),\n",
       " (('arnett', 'poehler'), 13.296532752806103),\n",
       " (('emt', 'voguing'), 13.296532752806103),\n",
       " (('triclosan', 'antibacterial'), 13.296532752806103),\n",
       " (('mitsubishimotor', 'Lancer'), 13.282374689809442),\n",
       " (('ivan', 'reitman'), 13.265673526313833),\n",
       " (('snowden', 'vindicate'), 13.260006876780988),\n",
       " (('conspiracy', 'theorie'), 13.259452100753814),\n",
       " (('trample', '$93'), 13.246201077255957)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pp.items(), key=lambda x:x[1], reverse=True)[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi(\"US\",\"us\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連続語を捉える"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### countinuous(語の前出現語の種類の数を調べる)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous(series,*,n=2):\n",
    "    dic = {}\n",
    "    for lis in series:\n",
    "        for i in range(len(lis)-1):\n",
    "            dic.setdefault(lis[i+1],set())\n",
    "            dic[lis[i+1]].add(lis[i])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:len(v) for k,v in continuous(news['uri']).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(series,*,n,count_thr=None,rate_thr=None):\n",
    "    dic = {}\n",
    "    for lis in series:\n",
    "        if len(lis)<n: continue\n",
    "        for i in range(len(lis)-n+1):\n",
    "            dic.setdefault(tuple(lis[i:i+n]),{'count':0})\n",
    "            dic[tuple(lis[i:i+n])]['count'] += 1\n",
    "    s = sum([v['count'] for v in dic.values()])\n",
    "    dic = {k:{\"count\":v[\"count\"],\"rate\":v['count']/s} for k,v in dic.items()}\n",
    "    if count_thr: dic = {k:v for k,v in dic.items() if v['count']>count_thr}\n",
    "    if rate_thr:  dic = {k:v for k,v in dic.items() if v['rate']>rate_thr}\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_words(li,ng):\n",
    "    for i,w in enumerate(li):\n",
    "        if i > len(li)-len(ng): break\n",
    "        if sum([w1!=w2 for w1,w2 in zip(li[i:i+len(ng)],ng)])==0:\n",
    "            li[i] = \"_\".join(li[i:i+len(ng)])\n",
    "            for j in range(i+len(ng)-1,i,-1): li.pop(j)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['uri_cat'] = news['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ng in get_ngram(news['uri_cat'],n=2,rate_thr=0.001).keys():\n",
    "    news['uri_cat'] = news['uri_cat'].apply(lambda u:concat_words(u,ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ng in get_ngram(news['uri_cat'],n=2,rate_thr=0.001).keys():\n",
    "    news['uri_cat'] = news['uri_cat'].apply(lambda u:concat_words(u,ng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ngram(news['uri_cat'],n=2,rate_thr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
