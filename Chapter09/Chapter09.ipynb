{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第9章: RNN, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80. ID番号への変換\n",
    "問題51で構築した学習データ中の単語にユニークなID番号を付与したい．学習データ中で最も頻出する単語に1，2番目に頻出する単語に2，……といった方法で，学習データ中で2回以上出現する単語にID番号を付与せよ．そして，与えられた単語列に対して，ID番号の列を返す関数を実装せよ．ただし，出現頻度が2回未満の単語のID番号はすべて0とせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for mode in [\"train\",\"test\",\"valid\"]:\n",
    "    exec(f\"{mode}_X = []\")\n",
    "    with open(f'{mode}_X.feature.txt') as f:\n",
    "        for line in f: exec(f\"{mode}_X.append(line.rstrip())\")\n",
    "    exec(f\"{mode}_Y = []\")\n",
    "    with open(f'{mode}_Y.txt') as f:\n",
    "        for line in f: exec(f\"{mode}_Y.append((int)(line.rstrip()))\")\n",
    "        exec(f\"{mode}_Y = np.array({mode}_Y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "for title in train_X:\n",
    "    for word in title.split(\" \"):\n",
    "        dic.setdefault(word,0)\n",
    "        dic[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_w2i(dic):\n",
    "    ids = {}\n",
    "    dic = {k:v for k,v in dic.items() if v>1}\n",
    "    for i,(k,v) in enumerate(sorted(dic.items(), key=lambda x:x[1], reverse=True),2):\n",
    "        ids[k] = i\n",
    "    def f(word):\n",
    "        if word not in ids.keys(): return 0\n",
    "        return ids[word]\n",
    "    return i+1,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_size, word2id = gen_w2i(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "text2ids = lambda text:np.array([word2id(w) for w in text.split(\" \")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 81. RNNによる予測\n",
    "ID番号で表現された単語列$x=(x_1,x_2,…,x_T)$がある．ただし，Tは単語列の長さ，$x_t\\in\\mathbb{R}^V$は単語のID番号のone-hot表記である（Vは単語の総数である）．再帰型ニューラルネットワーク（RNN: Recurrent Neural Network）を用い，単語列xからカテゴリyを予測するモデルとして，次式を実装せよ．\n",
    "$$\n",
    "\\vec{h}_0=0 \\\\\n",
    "\\vec{h}_t=\\vec{RNN}(emb(x_t),\\vec{h}_{t-1}) \\\\\n",
    "y = softmax(W^{(yh)}\\vec{h}_T+b^{(y)})\n",
    "$$\n",
    "ただし，$emb(x)\\in \\mathbb{R}^{d_w}$は単語埋め込み（単語のone-hot表記から単語ベクトルに変換する関数），$\\vec{h}_t\\in\\mathbb{R}^{d_h}$は時刻tの隠れ状態ベクトル，$\\vec{RNN}(x,h)$は入力xと前時刻の隠れ状態hから次状態を計算するRNNユニット，$W^{(yh)}\\in\\mathbb{R}^{L\\times d_h}$は隠れ状態ベクトルからカテゴリを予測するための行列，$b(y)\\in\\mathbb{R}^L$はバイアス項である（$d_w,d_h,L$はそれぞれ，単語埋め込みの次元数，隠れ状態ベクトルの次元数，ラベル数である）．RNNユニット$\\vec{RNN}(x,h)$には様々な構成が考えられるが，典型例として次式が挙げられる．\n",
    "$$\n",
    "\\vec{RNN}(x,h)=g(W^{(hx)}x+W^{(hh)}h+b^{(h)})\n",
    "$$\n",
    "ただし，$W^{(hx)}\\in\\mathbb{R}^{d_h\\times d_w}, W^{(hh)}\\in\\mathbb{R}^{d_h\\times d_h},b^{(h)}\\in\\mathbb{R}^{d_h}$はRNNユニットのパラメータ，gは活性化関数（例えばtanhやReLUなど）である．\n",
    "なお，この問題ではパラメータの学習を行わず，ランダムに初期化されたパラメータでyを計算するだけでよい．次元数などのハイパーパラメータは，dw=300,dh=50など，適当な値に設定せよ（以降の問題でも同様である）．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for mode in [\"train\",\"test\",\"valid\"]:\n",
    "    data[mode] = {}\n",
    "    data[mode][\"X\"] = [torch.tensor(text2ids(elm)) for elm in eval(f\"{mode}_X\")]\n",
    "    data[mode][\"Y\"] = eval(f\"{mode}_Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        if hidden is None:\n",
    "            device = self.parameters().__next__().device\n",
    "            hidden = torch.zeros(input.shape[0],self.hidden_size).to(device)\n",
    "        combined = torch.cat((input,hidden),1)\n",
    "        hidden = torch.tanh(self.i2h(combined))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_1(nn.Module):\n",
    "    def __init__(self, id_size, input_size, hidden_size, output_size):\n",
    "        super(Model_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(id_size, input_size)\n",
    "        self.rnn = RNN(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def predict(self, ids):\n",
    "        hidden = None\n",
    "        for i in range(ids.shape[1]):\n",
    "            x = self.embedding(ids[:,i])\n",
    "            hidden = self.rnn(x,hidden)\n",
    "        output = F.softmax(self.h2o(hidden),dim=1)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, ids, y):\n",
    "        return self.loss(self.predict(ids),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3209, 0.2208, 0.2425, 0.2158]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model_1(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "model.predict(data[\"train\"][\"X\"][10].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 82. 確率的勾配降下法による学習\n",
    "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題81で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[tips]\n",
    "+ model.eval() will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
    "+ torch.no_grad() impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, mode): self.X, self.Y = data[mode][\"X\"], data[mode][\"Y\"]\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "class LengthSampler(torch.utils.data.sampler.BatchSampler):\n",
    "    def __init__(self, mode, batch_size=1, shuffle=False):\n",
    "        X = data[mode][\"X\"]\n",
    "        X_sorted, indices = zip(*sorted(zip(X,range(len(X))),key=lambda tup:len(tup[0])))\n",
    "        self.dic = {}\n",
    "        for x,i in zip(X_sorted,indices):\n",
    "            self.dic.setdefault(len(x),[])\n",
    "            self.dic[len(x)].append(i)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.len = sum([math.ceil(len(v)/self.batch_size) for v in self.dic.values()])\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for indices in self.dic.values():\n",
    "            if self.shuffle: random.shuffle(indices)\n",
    "            while len(indices):\n",
    "                yield [indices.pop(0) for _ in range(self.batch_size) if len(indices)!=0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader = torch.utils.data.DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model,mode,device='cpu'):\n",
    "    count = 0;\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i,(x,y) in enumerate(zip(data[mode][\"X\"],data[mode][\"Y\"]),1):\n",
    "            x = x.to(device)\n",
    "            if y == model.predict(x.unsqueeze(0)).argmax(axis=1): count += 1\n",
    "    return count / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer,mode=\"train\",batch_size=1,shuffle=False,config={},device=None):\n",
    "    if device is None: device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    loader = DataLoader(DataSet(mode),batch_sampler=LengthSampler(mode,batch_size=batch_size,shuffle=shuffle))\n",
    "    values = {\"len\":len(loader), \"losses\":[], \"count\":0}\n",
    "    model.train().to(device)\n",
    "    for step,(x,y) in enumerate(loader,1):\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        bs = len(y)\n",
    "        loss = model(x,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        values[\"losses\"].append(loss)\n",
    "        values[\"count\"] += bs\n",
    "        if step%10==0:\n",
    "            print(\" \"*200+\"\\rtraining... [{:4d} epoch {:4d}/{:4d}] loss:{:.7f}\"\n",
    "                  .format(config[\"epoch\"] if \"epoch\" in config else \"-\", \n",
    "                          step,values[\"len\"], loss/bs),end=\"\\r\")\n",
    "    return sum(values[\"losses\"])/values[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,mode,batch_size=1,shuffle=False,config={},device=None):\n",
    "    if device is None: device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    loader = DataLoader(DataSet(mode),batch_sampler=LengthSampler(mode,batch_size=batch_size,shuffle=shuffle))\n",
    "    values = {\"len\":len(loader), \"losses\":[], \"count\":0}\n",
    "    model.eval().to(device)\n",
    "    with torch.no_grad():\n",
    "        for step,(x,y) in enumerate(loader,1):\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            bs = len(y)\n",
    "            loss = model(x,y)\n",
    "            values[\"losses\"].append(loss)\n",
    "            values[\"count\"] += bs\n",
    "            if step%10==0:\n",
    "                print(\" \"*100+\"\\revaluating... [{:4d} epoch {:4d}/{:4d}] loss:{:.7f}\"\n",
    "                  .format(config[\"epoch\"] if \"epoch\" in config else \"-\",\n",
    "                          step,values[\"len\"], loss/bs),end=\"\\r\")\n",
    "    return sum(values[\"losses\"])/values[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_state(es,epoch,train_loss,valid_loss,train_accuracy,valid_accuracy,test_accuracy,end=\"\\n\"):\n",
    "    print(\"es[{}/{}]{:4d} epoch train:{:.7f}, valid:{:.7f}, train_acc:{:.3f}%, valid_acc:{:.3f}%, (test_acc:{:.3f}%)\"\n",
    "          .format(es[0],es[1],epoch,train_loss,valid_loss,train_accuracy,valid_accuracy,test_accuracy),end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es[0/20]   0 epoch train:0.0266694, valid:0.0209152, train_acc:59.754%, valid_acc:58.996%, (test_acc:59.370%)\n",
      "es[0/20]   1 epoch train:0.0235360, valid:0.0199491, train_acc:64.852%, valid_acc:65.142%, (test_acc:63.043%)\n",
      "es[0/20]   2 epoch train:0.0226922, valid:0.0203697, train_acc:63.418%, valid_acc:62.444%, (test_acc:60.945%)\n",
      "es[1/20]   3 epoch train:0.0224812, valid:0.0195993, train_acc:68.900%, valid_acc:66.942%, (test_acc:65.892%)\n",
      "es[0/20]   4 epoch train:0.0222348, valid:0.0195875, train_acc:70.193%, valid_acc:68.591%, (test_acc:67.991%)\n",
      "es[0/20]   5 epoch train:0.0220867, valid:0.0193637, train_acc:69.528%, valid_acc:68.441%, (test_acc:66.492%)\n",
      "es[0/20]   6 epoch train:0.0218845, valid:0.0196264, train_acc:69.912%, valid_acc:67.841%, (test_acc:67.091%)\n",
      "es[1/20]   7 epoch train:0.0217981, valid:0.0192780, train_acc:71.627%, valid_acc:70.165%, (test_acc:69.565%)\n",
      "es[0/20]   8 epoch train:0.0216871, valid:0.0193945, train_acc:71.655%, valid_acc:69.640%, (test_acc:68.441%)\n",
      "es[1/20]   9 epoch train:0.0215023, valid:0.0193228, train_acc:72.180%, valid_acc:69.715%, (test_acc:69.565%)\n",
      "es[2/20]  10 epoch train:0.0214224, valid:0.0192628, train_acc:73.501%, valid_acc:70.390%, (test_acc:69.865%)\n",
      "es[0/20]  11 epoch train:0.0213580, valid:0.0191735, train_acc:74.531%, valid_acc:71.064%, (test_acc:70.840%)\n",
      "es[0/20]  12 epoch train:0.0212132, valid:0.0194596, train_acc:72.948%, valid_acc:68.816%, (test_acc:69.115%)\n",
      "es[1/20]  13 epoch train:0.0211096, valid:0.0190455, train_acc:75.712%, valid_acc:71.589%, (test_acc:71.364%)\n",
      "es[0/20]  14 epoch train:0.0210406, valid:0.0191223, train_acc:74.672%, valid_acc:70.990%, (test_acc:70.840%)\n",
      "es[1/20]  15 epoch train:0.0210217, valid:0.0188674, train_acc:76.312%, valid_acc:73.013%, (test_acc:71.964%)\n",
      "es[0/20]  16 epoch train:0.0208723, valid:0.0189382, train_acc:76.368%, valid_acc:72.564%, (test_acc:72.039%)\n",
      "es[1/20]  17 epoch train:0.0208163, valid:0.0189019, train_acc:77.043%, valid_acc:72.939%, (test_acc:71.889%)\n",
      "es[2/20]  18 epoch train:0.0207223, valid:0.0189468, train_acc:76.883%, valid_acc:72.264%, (test_acc:71.514%)\n",
      "es[3/20]  19 epoch train:0.0206555, valid:0.0190530, train_acc:75.900%, valid_acc:71.139%, (test_acc:70.390%)\n",
      "es[4/20]  20 epoch train:0.0206235, valid:0.0188538, train_acc:78.598%, valid_acc:73.463%, (test_acc:72.639%)\n",
      "es[0/20]  21 epoch train:0.0206644, valid:0.0188659, train_acc:77.352%, valid_acc:73.238%, (test_acc:70.990%)\n",
      "es[1/20]  22 epoch train:0.0205010, valid:0.0190614, train_acc:77.942%, valid_acc:73.088%, (test_acc:71.739%)\n",
      "es[2/20]  23 epoch train:0.0204326, valid:0.0187933, train_acc:79.104%, valid_acc:73.313%, (test_acc:72.564%)\n",
      "es[0/20]  24 epoch train:0.0202946, valid:0.0191920, train_acc:74.963%, valid_acc:70.315%, (test_acc:68.891%)\n",
      "es[1/20]  25 epoch train:0.0202583, valid:0.0189272, train_acc:77.324%, valid_acc:72.864%, (test_acc:72.189%)\n",
      "es[2/20]  26 epoch train:0.0203530, valid:0.0190440, train_acc:77.474%, valid_acc:72.114%, (test_acc:71.889%)\n",
      "es[3/20]  27 epoch train:0.0201907, valid:0.0190046, train_acc:77.830%, valid_acc:72.639%, (test_acc:71.139%)\n",
      "es[4/20]  28 epoch train:0.0201470, valid:0.0187322, train_acc:79.976%, valid_acc:74.213%, (test_acc:72.264%)\n",
      "es[0/20]  29 epoch train:0.0199728, valid:0.0190091, train_acc:80.669%, valid_acc:74.288%, (test_acc:73.238%)\n",
      "es[1/20]  30 epoch train:0.0199435, valid:0.0194113, train_acc:80.678%, valid_acc:74.213%, (test_acc:73.763%)\n",
      "es[2/20]  31 epoch train:0.0201000, valid:0.0194376, train_acc:80.538%, valid_acc:74.363%, (test_acc:74.063%)\n",
      "es[3/20]  32 epoch train:0.0199343, valid:0.0193093, train_acc:81.306%, valid_acc:73.763%, (test_acc:73.313%)\n",
      "es[4/20]  33 epoch train:0.0198006, valid:0.0191980, train_acc:76.593%, valid_acc:71.064%, (test_acc:69.790%)\n",
      "es[5/20]  34 epoch train:0.0198337, valid:0.0198929, train_acc:73.904%, valid_acc:68.516%, (test_acc:67.616%)\n",
      "es[6/20]  35 epoch train:0.0197846, valid:0.0195809, train_acc:78.804%, valid_acc:72.714%, (test_acc:71.514%)\n",
      "es[7/20]  36 epoch train:0.0198544, valid:0.0188117, train_acc:81.681%, valid_acc:74.138%, (test_acc:74.138%)\n",
      "es[8/20]  37 epoch train:0.0197083, valid:0.0191004, train_acc:80.341%, valid_acc:73.088%, (test_acc:72.264%)\n",
      "es[9/20]  38 epoch train:0.0196790, valid:0.0196188, train_acc:82.478%, valid_acc:72.564%, (test_acc:73.988%)\n",
      "es[10/20]  39 epoch train:0.0195630, valid:0.0198532, train_acc:80.135%, valid_acc:73.238%, (test_acc:71.739%)\n",
      "es[11/20]  40 epoch train:0.0198150, valid:0.0187752, train_acc:81.850%, valid_acc:74.513%, (test_acc:73.688%)\n",
      "es[12/20]  41 epoch train:0.0195200, valid:0.0191455, train_acc:82.103%, valid_acc:74.588%, (test_acc:72.939%)\n",
      "es[13/20]  42 epoch train:0.0193927, valid:0.0192156, train_acc:81.016%, valid_acc:72.939%, (test_acc:71.439%)\n",
      "es[14/20]  43 epoch train:0.0193744, valid:0.0192829, train_acc:83.555%, valid_acc:74.738%, (test_acc:73.988%)\n",
      "es[15/20]  44 epoch train:0.0192747, valid:0.0191261, train_acc:84.492%, valid_acc:74.588%, (test_acc:74.438%)\n",
      "es[16/20]  45 epoch train:0.0192301, valid:0.0186202, train_acc:83.574%, valid_acc:75.787%, (test_acc:72.864%)\n",
      "es[0/20]  46 epoch train:0.0191576, valid:0.0187910, train_acc:82.403%, valid_acc:73.913%, (test_acc:71.814%)\n",
      "es[1/20]  47 epoch train:0.0191189, valid:0.0186283, train_acc:83.340%, valid_acc:75.112%, (test_acc:72.639%)\n",
      "es[2/20]  48 epoch train:0.0190634, valid:0.0185157, train_acc:85.167%, valid_acc:76.462%, (test_acc:74.438%)\n",
      "es[0/20]  49 epoch train:0.0189904, valid:0.0185687, train_acc:85.120%, valid_acc:75.487%, (test_acc:73.613%)\n",
      "es[1/20]  50 epoch train:0.0189911, valid:0.0184802, train_acc:85.167%, valid_acc:75.487%, (test_acc:74.888%)\n",
      "es[0/20]  51 epoch train:0.0188781, valid:0.0184674, train_acc:85.439%, valid_acc:76.912%, (test_acc:74.288%)\n",
      "es[0/20]  52 epoch train:0.0189258, valid:0.0186075, train_acc:86.226%, valid_acc:75.712%, (test_acc:74.963%)\n",
      "es[1/20]  53 epoch train:0.0188568, valid:0.0185355, train_acc:86.900%, valid_acc:76.162%, (test_acc:75.337%)\n",
      "es[2/20]  54 epoch train:0.0187859, valid:0.0186038, train_acc:86.469%, valid_acc:75.412%, (test_acc:75.112%)\n",
      "es[3/20]  55 epoch train:0.0187989, valid:0.0185512, train_acc:86.132%, valid_acc:76.162%, (test_acc:74.588%)\n",
      "es[4/20]  56 epoch train:0.0187524, valid:0.0184459, train_acc:87.022%, valid_acc:76.387%, (test_acc:75.112%)\n",
      "es[0/20]  57 epoch train:0.0186691, valid:0.0188113, train_acc:86.019%, valid_acc:75.562%, (test_acc:73.988%)\n",
      "es[1/20]  58 epoch train:0.0188497, valid:0.0192701, train_acc:85.223%, valid_acc:75.337%, (test_acc:73.163%)\n",
      "es[2/20]  59 epoch train:0.0186846, valid:0.0189730, train_acc:86.010%, valid_acc:75.187%, (test_acc:73.538%)\n",
      "es[3/20]  60 epoch train:0.0186120, valid:0.0190877, train_acc:87.612%, valid_acc:76.387%, (test_acc:75.112%)\n",
      "es[4/20]  61 epoch train:0.0185884, valid:0.0184979, train_acc:87.687%, valid_acc:76.762%, (test_acc:75.112%)\n",
      "es[5/20]  62 epoch train:0.0185936, valid:0.0185248, train_acc:87.472%, valid_acc:76.387%, (test_acc:74.888%)\n",
      "es[6/20]  63 epoch train:0.0185706, valid:0.0187091, train_acc:86.600%, valid_acc:75.562%, (test_acc:74.138%)\n",
      "es[7/20]  64 epoch train:0.0184968, valid:0.0185975, train_acc:88.268%, valid_acc:76.837%, (test_acc:75.562%)\n",
      "es[8/20]  65 epoch train:0.0184725, valid:0.0190984, train_acc:88.072%, valid_acc:76.162%, (test_acc:74.438%)\n",
      "es[9/20]  66 epoch train:0.0185024, valid:0.0191185, train_acc:87.997%, valid_acc:76.612%, (test_acc:74.513%)\n",
      "es[10/20]  67 epoch train:0.0184671, valid:0.0191905, train_acc:86.675%, valid_acc:75.487%, (test_acc:73.988%)\n",
      "es[11/20]  68 epoch train:0.0186080, valid:0.0191430, train_acc:87.210%, valid_acc:74.663%, (test_acc:74.213%)\n",
      "es[12/20]  69 epoch train:0.0185772, valid:0.0190263, train_acc:84.811%, valid_acc:74.963%, (test_acc:72.639%)\n",
      "es[13/20]  70 epoch train:0.0186686, valid:0.0193328, train_acc:86.853%, valid_acc:75.712%, (test_acc:74.588%)\n",
      "es[14/20]  71 epoch train:0.0184638, valid:0.0184963, train_acc:86.469%, valid_acc:76.312%, (test_acc:74.288%)\n",
      "es[15/20]  72 epoch train:0.0184301, valid:0.0188504, train_acc:88.540%, valid_acc:77.286%, (test_acc:75.337%)\n",
      "es[16/20]  73 epoch train:0.0183749, valid:0.0192308, train_acc:88.268%, valid_acc:76.012%, (test_acc:74.213%)\n",
      "es[17/20]  74 epoch train:0.0183886, valid:0.0186355, train_acc:88.521%, valid_acc:76.237%, (test_acc:74.738%)\n",
      "es[18/20]  75 epoch train:0.0183788, valid:0.0186963, train_acc:87.266%, valid_acc:75.637%, (test_acc:73.688%)\n",
      "es[19/20]  76 epoch train:0.0183797, valid:0.0187279, train_acc:89.318%, valid_acc:76.762%, (test_acc:74.888%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = Model_1(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "\n",
    "for epoch in range(10000):\n",
    "    train_loss = train(model,optimizer,batch_size=50,shuffle=True,config={\"epoch\":epoch},device=\"cpu\")\n",
    "    valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device=\"cpu\")\n",
    "    print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "    if valid_loss < config[\"mvl\"]: \n",
    "        config[\"mvl\"] = valid_loss\n",
    "        config[\"es\"][0] = 0\n",
    "    else: config[\"es\"][0] += 1\n",
    "    if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 83. ミニバッチ化・GPU上での学習\n",
    "問題82のコードを改変し，B事例ごとに損失・勾配を計算して学習を行えるようにせよ（Bの値は適当に選べ）．また，GPU上で学習を実行せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es[0/20]   0 epoch train:0.1144382, valid:0.0207029, train_acc:59.792%, valid_acc:58.396%, (test_acc:55.922%)\n",
      "es[0/20]   1 epoch train:0.1113043, valid:0.0207874, train_acc:61.722%, valid_acc:61.169%, (test_acc:59.070%)\n",
      "es[1/20]   2 epoch train:0.1111997, valid:0.0204562, train_acc:62.725%, valid_acc:61.394%, (test_acc:60.645%)\n",
      "es[0/20]   3 epoch train:0.1104643, valid:0.0201060, train_acc:66.342%, valid_acc:66.342%, (test_acc:66.792%)\n",
      "es[0/20]   4 epoch train:0.1088346, valid:0.0201130, train_acc:67.279%, valid_acc:65.817%, (test_acc:66.567%)\n",
      "es[1/20]   5 epoch train:0.1078692, valid:0.0200516, train_acc:68.394%, valid_acc:66.192%, (test_acc:67.466%)\n",
      "es[0/20]   6 epoch train:0.1066503, valid:0.0199195, train_acc:69.921%, valid_acc:67.091%, (test_acc:68.441%)\n",
      "es[0/20]   7 epoch train:0.1052698, valid:0.0198243, train_acc:71.036%, valid_acc:67.391%, (test_acc:68.816%)\n",
      "es[0/20]   8 epoch train:0.1045785, valid:0.0196981, train_acc:71.814%, valid_acc:67.766%, (test_acc:69.040%)\n",
      "es[0/20]   9 epoch train:0.1035575, valid:0.0197146, train_acc:72.151%, valid_acc:68.816%, (test_acc:69.040%)\n",
      "es[1/20]  10 epoch train:0.1028802, valid:0.0197750, train_acc:72.892%, valid_acc:67.841%, (test_acc:68.366%)\n",
      "es[2/20]  11 epoch train:0.1020537, valid:0.0192368, train_acc:74.382%, valid_acc:70.240%, (test_acc:69.340%)\n",
      "es[0/20]  12 epoch train:0.1013977, valid:0.0188955, train_acc:74.822%, valid_acc:70.015%, (test_acc:70.015%)\n",
      "es[0/20]  13 epoch train:0.1012885, valid:0.0189478, train_acc:74.906%, valid_acc:69.415%, (test_acc:70.090%)\n",
      "es[1/20]  14 epoch train:0.1007723, valid:0.0190491, train_acc:74.972%, valid_acc:70.015%, (test_acc:69.340%)\n",
      "es[2/20]  15 epoch train:0.1001618, valid:0.0189119, train_acc:75.300%, valid_acc:70.015%, (test_acc:70.240%)\n",
      "es[3/20]  16 epoch train:0.1000341, valid:0.0189525, train_acc:76.106%, valid_acc:70.915%, (test_acc:70.690%)\n",
      "es[4/20]  17 epoch train:0.0992306, valid:0.0187382, train_acc:76.668%, valid_acc:71.214%, (test_acc:70.540%)\n",
      "es[0/20]  18 epoch train:0.0989408, valid:0.0186851, train_acc:77.024%, valid_acc:70.990%, (test_acc:69.940%)\n",
      "es[0/20]  19 epoch train:0.0985111, valid:0.0191390, train_acc:75.019%, valid_acc:69.340%, (test_acc:68.816%)\n",
      "es[1/20]  20 epoch train:0.0988059, valid:0.0185860, train_acc:77.333%, valid_acc:70.990%, (test_acc:69.865%)\n",
      "es[0/20]  21 epoch train:0.0978229, valid:0.0190128, train_acc:78.345%, valid_acc:71.214%, (test_acc:70.915%)\n",
      "es[1/20]  22 epoch train:0.0970480, valid:0.0186256, train_acc:77.811%, valid_acc:70.765%, (test_acc:70.315%)\n",
      "es[2/20]  23 epoch train:0.0970511, valid:0.0187227, train_acc:79.207%, valid_acc:71.064%, (test_acc:70.840%)\n",
      "es[3/20]  24 epoch train:0.0964115, valid:0.0186565, train_acc:78.842%, valid_acc:70.240%, (test_acc:70.540%)\n",
      "es[4/20]  25 epoch train:0.0960332, valid:0.0186303, train_acc:80.022%, valid_acc:71.139%, (test_acc:70.615%)\n",
      "es[5/20]  26 epoch train:0.0953812, valid:0.0186569, train_acc:80.135%, valid_acc:70.315%, (test_acc:71.064%)\n",
      "es[6/20]  27 epoch train:0.0953603, valid:0.0185399, train_acc:80.388%, valid_acc:71.289%, (test_acc:71.064%)\n",
      "es[0/20]  28 epoch train:0.0951751, valid:0.0186092, train_acc:80.407%, valid_acc:71.064%, (test_acc:70.465%)\n",
      "es[1/20]  29 epoch train:0.0947448, valid:0.0186886, train_acc:80.678%, valid_acc:70.765%, (test_acc:71.214%)\n",
      "es[2/20]  30 epoch train:0.0946329, valid:0.0187465, train_acc:80.828%, valid_acc:70.915%, (test_acc:71.289%)\n",
      "es[3/20]  31 epoch train:0.0942661, valid:0.0187233, train_acc:81.437%, valid_acc:70.465%, (test_acc:71.214%)\n",
      "es[4/20]  32 epoch train:0.0940960, valid:0.0187221, train_acc:81.615%, valid_acc:70.690%, (test_acc:70.990%)\n",
      "es[5/20]  33 epoch train:0.0940298, valid:0.0186327, train_acc:81.156%, valid_acc:71.139%, (test_acc:71.289%)\n",
      "es[6/20]  34 epoch train:0.0938573, valid:0.0186183, train_acc:82.084%, valid_acc:71.364%, (test_acc:70.840%)\n",
      "es[7/20]  35 epoch train:0.0937948, valid:0.0184623, train_acc:81.784%, valid_acc:71.739%, (test_acc:71.589%)\n",
      "es[0/20]  36 epoch train:0.0938617, valid:0.0188723, train_acc:80.444%, valid_acc:68.891%, (test_acc:69.940%)\n",
      "es[1/20]  37 epoch train:0.0944726, valid:0.0184961, train_acc:81.822%, valid_acc:71.589%, (test_acc:70.915%)\n",
      "es[2/20]  38 epoch train:0.0937179, valid:0.0184983, train_acc:82.281%, valid_acc:71.214%, (test_acc:70.690%)\n",
      "es[3/20]  39 epoch train:0.0931713, valid:0.0184154, train_acc:82.609%, valid_acc:71.739%, (test_acc:71.064%)\n",
      "es[0/20]  40 epoch train:0.0929360, valid:0.0185930, train_acc:82.721%, valid_acc:71.364%, (test_acc:71.289%)\n",
      "es[1/20]  41 epoch train:0.0929336, valid:0.0186197, train_acc:82.796%, valid_acc:71.889%, (test_acc:70.990%)\n",
      "es[2/20]  42 epoch train:0.0932074, valid:0.0188932, train_acc:82.843%, valid_acc:71.064%, (test_acc:70.090%)\n",
      "es[3/20]  43 epoch train:0.0925983, valid:0.0188543, train_acc:83.077%, valid_acc:70.390%, (test_acc:70.690%)\n",
      "es[4/20]  44 epoch train:0.0925081, valid:0.0186363, train_acc:82.403%, valid_acc:72.114%, (test_acc:71.589%)\n",
      "es[5/20]  45 epoch train:0.0923837, valid:0.0188071, train_acc:83.452%, valid_acc:71.439%, (test_acc:71.364%)\n",
      "es[6/20]  46 epoch train:0.0923144, valid:0.0187694, train_acc:83.639%, valid_acc:71.064%, (test_acc:71.064%)\n",
      "es[7/20]  47 epoch train:0.0920848, valid:0.0187187, train_acc:83.443%, valid_acc:71.214%, (test_acc:71.364%)\n",
      "es[8/20]  48 epoch train:0.0917808, valid:0.0186848, train_acc:83.958%, valid_acc:71.889%, (test_acc:70.915%)\n",
      "es[9/20]  49 epoch train:0.0913940, valid:0.0188636, train_acc:84.295%, valid_acc:71.439%, (test_acc:70.990%)\n",
      "es[10/20]  50 epoch train:0.0913550, valid:0.0188240, train_acc:84.408%, valid_acc:71.964%, (test_acc:71.064%)\n",
      "es[11/20]  51 epoch train:0.0919296, valid:0.0187635, train_acc:83.864%, valid_acc:71.739%, (test_acc:71.739%)\n",
      "es[12/20]  52 epoch train:0.0919910, valid:0.0187770, train_acc:83.696%, valid_acc:71.889%, (test_acc:70.540%)\n",
      "es[13/20]  53 epoch train:0.0917888, valid:0.0188312, train_acc:83.817%, valid_acc:71.814%, (test_acc:71.439%)\n",
      "es[14/20]  54 epoch train:0.0921573, valid:0.0189159, train_acc:83.583%, valid_acc:71.289%, (test_acc:70.540%)\n",
      "es[15/20]  55 epoch train:0.0921256, valid:0.0188616, train_acc:83.724%, valid_acc:71.589%, (test_acc:71.289%)\n",
      "es[16/20]  56 epoch train:0.0915718, valid:0.0187470, train_acc:84.333%, valid_acc:72.639%, (test_acc:71.289%)\n",
      "es[17/20]  57 epoch train:0.0915166, valid:0.0187714, train_acc:84.145%, valid_acc:72.114%, (test_acc:70.990%)\n",
      "es[18/20]  58 epoch train:0.0914649, valid:0.0187863, train_acc:84.539%, valid_acc:72.189%, (test_acc:71.439%)\n",
      "es[19/20]  59 epoch train:0.0912764, valid:0.0186168, train_acc:83.996%, valid_acc:71.889%, (test_acc:71.964%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = Model_1(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train(model,optimizer,batch_size=10,shuffle=True,config={\"epoch\":epoch},device='cuda')\n",
    "    valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device='cuda')\n",
    "    print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "    if valid_loss < config[\"mvl\"]: \n",
    "        config[\"mvl\"] = valid_loss\n",
    "        config[\"es\"][0] = 0\n",
    "    else: config[\"es\"][0] += 1\n",
    "    if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 84. 単語ベクトルの導入\n",
    "事前学習済みの単語ベクトル（例えば，Google Newsデータセット（約1,000億単語）での学習済み単語ベクトル）で単語埋め込みemb(x)を初期化し，学習せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "w2v = KeyedVectors.load_word2vec_format('../Chapter07/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vecs(dic):\n",
    "    vecs = [np.random.random(300) for _ in range(2)]\n",
    "    dic = {k:v for k,v in dic.items() if v>1}\n",
    "    for i,(k,v) in enumerate(sorted(dic.items(), key=lambda x:x[1], reverse=True),2):\n",
    "        if k in w2v: vecs.append(w2v[k])\n",
    "        else: vecs.append(np.random.random(300))\n",
    "    return np.array(vecs)\n",
    "vectors = gen_vecs(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_2(nn.Module):\n",
    "    def __init__(self, id_size, input_size, hidden_size, output_size):\n",
    "        super(Model_2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(id_size, input_size).from_pretrained(torch.FloatTensor(vectors))\n",
    "        self.embedding.weight.requires_grad=True\n",
    "        self.rnn = RNN(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def predict(self, ids):\n",
    "        hidden = None\n",
    "        for i in range(ids.shape[1]):\n",
    "            x = self.embedding(ids[:,i])\n",
    "            hidden = self.rnn(x,hidden)\n",
    "        output = F.softmax(self.h2o(hidden),dim=1)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, ids, y):\n",
    "        return self.loss(self.predict(ids),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es[0/20]   0 epoch train:0.1197914, valid:0.0222728, train_acc:47.114%, valid_acc:46.402%, (test_acc:46.477%)\n",
      "es[0/20]   1 epoch train:0.1331808, valid:0.0255631, train_acc:38.512%, valid_acc:35.907%, (test_acc:39.205%)\n",
      "es[1/20]   2 epoch train:0.1262791, valid:0.0238661, train_acc:53.542%, valid_acc:50.975%, (test_acc:51.949%)\n",
      "es[2/20]   3 epoch train:0.1180982, valid:0.0261656, train_acc:33.639%, valid_acc:30.735%, (test_acc:32.309%)\n",
      "es[3/20]   4 epoch train:0.1206906, valid:0.0231487, train_acc:46.280%, valid_acc:48.276%, (test_acc:46.477%)\n",
      "es[4/20]   5 epoch train:0.1224507, valid:0.0216021, train_acc:55.557%, valid_acc:55.772%, (test_acc:56.372%)\n",
      "es[0/20]   6 epoch train:0.1136432, valid:0.0203864, train_acc:62.987%, valid_acc:62.219%, (test_acc:61.919%)\n",
      "es[0/20]   7 epoch train:0.1048072, valid:0.0194056, train_acc:66.698%, valid_acc:65.892%, (test_acc:64.843%)\n",
      "es[0/20]   8 epoch train:0.1029371, valid:0.0197485, train_acc:66.942%, valid_acc:65.892%, (test_acc:65.292%)\n",
      "es[1/20]   9 epoch train:0.1022315, valid:0.0190840, train_acc:70.427%, valid_acc:68.741%, (test_acc:68.291%)\n",
      "es[0/20]  10 epoch train:0.1014014, valid:0.0193628, train_acc:67.204%, valid_acc:66.417%, (test_acc:64.093%)\n",
      "es[1/20]  11 epoch train:0.1007903, valid:0.0198943, train_acc:66.051%, valid_acc:65.592%, (test_acc:66.717%)\n",
      "es[2/20]  12 epoch train:0.1014958, valid:0.0185153, train_acc:73.679%, valid_acc:73.388%, (test_acc:72.564%)\n",
      "es[0/20]  13 epoch train:0.1002690, valid:0.0212620, train_acc:54.160%, valid_acc:53.673%, (test_acc:51.199%)\n",
      "es[1/20]  14 epoch train:0.1025928, valid:0.0180990, train_acc:75.890%, valid_acc:75.337%, (test_acc:74.438%)\n",
      "es[0/20]  15 epoch train:0.1001052, valid:0.0181768, train_acc:76.546%, valid_acc:76.237%, (test_acc:75.487%)\n",
      "es[1/20]  16 epoch train:0.0989449, valid:0.0182511, train_acc:74.222%, valid_acc:74.438%, (test_acc:73.613%)\n",
      "es[2/20]  17 epoch train:0.1001775, valid:0.0181445, train_acc:75.637%, valid_acc:75.262%, (test_acc:74.513%)\n",
      "es[3/20]  18 epoch train:0.0989313, valid:0.0181501, train_acc:75.469%, valid_acc:75.487%, (test_acc:74.213%)\n",
      "es[4/20]  19 epoch train:0.1003469, valid:0.0189781, train_acc:71.027%, valid_acc:71.889%, (test_acc:69.340%)\n",
      "es[5/20]  20 epoch train:0.1004056, valid:0.0196963, train_acc:65.648%, valid_acc:65.292%, (test_acc:63.868%)\n",
      "es[6/20]  21 epoch train:0.1002313, valid:0.0187381, train_acc:71.889%, valid_acc:71.589%, (test_acc:70.690%)\n",
      "es[7/20]  22 epoch train:0.0991969, valid:0.0184142, train_acc:77.118%, valid_acc:76.087%, (test_acc:76.012%)\n",
      "es[8/20]  23 epoch train:0.0979374, valid:0.0179188, train_acc:76.668%, valid_acc:76.387%, (test_acc:75.787%)\n",
      "es[0/20]  24 epoch train:0.0976492, valid:0.0188111, train_acc:74.466%, valid_acc:74.063%, (test_acc:74.063%)\n",
      "es[1/20]  25 epoch train:0.0986436, valid:0.0177990, train_acc:77.361%, valid_acc:76.987%, (test_acc:75.712%)\n",
      "es[0/20]  26 epoch train:0.0988200, valid:0.0181221, train_acc:76.743%, valid_acc:75.337%, (test_acc:74.963%)\n",
      "es[1/20]  27 epoch train:0.0984509, valid:0.0177640, train_acc:76.846%, valid_acc:76.087%, (test_acc:74.813%)\n",
      "es[0/20]  28 epoch train:0.0980165, valid:0.0181145, train_acc:76.331%, valid_acc:75.487%, (test_acc:74.288%)\n",
      "es[1/20]  29 epoch train:0.0991531, valid:0.0182848, train_acc:74.869%, valid_acc:73.763%, (test_acc:74.438%)\n",
      "es[2/20]  30 epoch train:0.0982921, valid:0.0179122, train_acc:77.774%, valid_acc:76.312%, (test_acc:76.087%)\n",
      "es[3/20]  31 epoch train:0.0975228, valid:0.0178820, train_acc:78.130%, valid_acc:76.762%, (test_acc:76.462%)\n",
      "es[4/20]  32 epoch train:0.0978114, valid:0.0179885, train_acc:77.614%, valid_acc:76.162%, (test_acc:76.387%)\n",
      "es[5/20]  33 epoch train:0.0972060, valid:0.0179140, train_acc:77.811%, valid_acc:76.762%, (test_acc:75.937%)\n",
      "es[6/20]  34 epoch train:0.0972296, valid:0.0179466, train_acc:78.120%, valid_acc:76.612%, (test_acc:76.387%)\n",
      "es[7/20]  35 epoch train:0.0967519, valid:0.0178168, train_acc:78.270%, valid_acc:76.837%, (test_acc:76.012%)\n",
      "es[8/20]  36 epoch train:0.0972897, valid:0.0180788, train_acc:76.321%, valid_acc:75.487%, (test_acc:75.112%)\n",
      "es[9/20]  37 epoch train:0.0966794, valid:0.0177325, train_acc:79.292%, valid_acc:77.811%, (test_acc:77.736%)\n",
      "es[0/20]  38 epoch train:0.0958589, valid:0.0177681, train_acc:78.907%, valid_acc:78.186%, (test_acc:76.762%)\n",
      "es[1/20]  39 epoch train:0.0962431, valid:0.0177059, train_acc:79.507%, valid_acc:78.261%, (test_acc:77.511%)\n",
      "es[0/20]  40 epoch train:0.0957371, valid:0.0178516, train_acc:79.385%, valid_acc:77.211%, (test_acc:77.286%)\n",
      "es[1/20]  41 epoch train:0.0957288, valid:0.0177411, train_acc:79.844%, valid_acc:77.886%, (test_acc:77.661%)\n",
      "es[2/20]  42 epoch train:0.0954826, valid:0.0177491, train_acc:79.591%, valid_acc:78.111%, (test_acc:78.411%)\n",
      "es[3/20]  43 epoch train:0.0956928, valid:0.0176836, train_acc:79.779%, valid_acc:77.661%, (test_acc:77.586%)\n",
      "es[0/20]  44 epoch train:0.0952552, valid:0.0177928, train_acc:79.470%, valid_acc:77.736%, (test_acc:77.811%)\n",
      "es[1/20]  45 epoch train:0.0956705, valid:0.0182419, train_acc:76.659%, valid_acc:75.262%, (test_acc:74.888%)\n",
      "es[2/20]  46 epoch train:0.0991907, valid:0.0181259, train_acc:76.771%, valid_acc:75.262%, (test_acc:75.487%)\n",
      "es[3/20]  47 epoch train:0.0963843, valid:0.0178359, train_acc:79.095%, valid_acc:77.211%, (test_acc:77.361%)\n",
      "es[4/20]  48 epoch train:0.0956622, valid:0.0178010, train_acc:80.032%, valid_acc:77.736%, (test_acc:79.010%)\n",
      "es[5/20]  49 epoch train:0.0953036, valid:0.0176724, train_acc:80.482%, valid_acc:78.486%, (test_acc:79.460%)\n",
      "es[0/20]  50 epoch train:0.0950624, valid:0.0178340, train_acc:79.901%, valid_acc:77.586%, (test_acc:77.886%)\n",
      "es[1/20]  51 epoch train:0.0949025, valid:0.0176875, train_acc:81.016%, valid_acc:78.486%, (test_acc:78.711%)\n",
      "es[2/20]  52 epoch train:0.0988642, valid:0.0228577, train_acc:51.424%, valid_acc:51.874%, (test_acc:52.924%)\n",
      "es[3/20]  53 epoch train:0.1054936, valid:0.0193615, train_acc:73.669%, valid_acc:72.339%, (test_acc:72.939%)\n",
      "es[4/20]  54 epoch train:0.0987164, valid:0.0180542, train_acc:76.827%, valid_acc:75.937%, (test_acc:76.012%)\n",
      "es[5/20]  55 epoch train:0.0972589, valid:0.0178959, train_acc:78.139%, valid_acc:76.537%, (test_acc:76.462%)\n",
      "es[6/20]  56 epoch train:0.0965123, valid:0.0182267, train_acc:75.843%, valid_acc:74.213%, (test_acc:75.037%)\n",
      "es[7/20]  57 epoch train:0.0965640, valid:0.0177529, train_acc:79.189%, valid_acc:77.511%, (test_acc:78.486%)\n",
      "es[8/20]  58 epoch train:0.0977332, valid:0.0195405, train_acc:71.936%, valid_acc:69.640%, (test_acc:70.540%)\n",
      "es[9/20]  59 epoch train:0.0978646, valid:0.0180570, train_acc:77.633%, valid_acc:75.412%, (test_acc:76.687%)\n",
      "es[10/20]  60 epoch train:0.0979413, valid:0.0180152, train_acc:78.073%, valid_acc:76.012%, (test_acc:77.211%)\n",
      "es[11/20]  61 epoch train:0.0992143, valid:0.0179424, train_acc:77.155%, valid_acc:76.312%, (test_acc:76.687%)\n",
      "es[12/20]  62 epoch train:0.0975459, valid:0.0181585, train_acc:77.249%, valid_acc:75.862%, (test_acc:75.412%)\n",
      "es[13/20]  63 epoch train:0.0974500, valid:0.0179688, train_acc:77.230%, valid_acc:76.237%, (test_acc:75.562%)\n",
      "es[14/20]  64 epoch train:0.0970715, valid:0.0178000, train_acc:78.514%, valid_acc:77.136%, (test_acc:77.586%)\n",
      "es[15/20]  65 epoch train:0.0975104, valid:0.0193747, train_acc:68.047%, valid_acc:66.942%, (test_acc:67.091%)\n",
      "es[16/20]  66 epoch train:0.0977096, valid:0.0184793, train_acc:74.569%, valid_acc:73.613%, (test_acc:71.514%)\n",
      "es[17/20]  67 epoch train:0.0964742, valid:0.0179350, train_acc:79.142%, valid_acc:77.061%, (test_acc:76.912%)\n",
      "es[18/20]  68 epoch train:0.0959209, valid:0.0180884, train_acc:78.083%, valid_acc:76.162%, (test_acc:76.837%)\n",
      "es[19/20]  69 epoch train:0.0962095, valid:0.0183963, train_acc:75.618%, valid_acc:73.613%, (test_acc:73.463%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = Model_2(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train(model,optimizer,batch_size=10,shuffle=True,config={\"epoch\":epoch},device='cuda')\n",
    "    valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device='cuda')\n",
    "    print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "    if valid_loss < config[\"mvl\"]: \n",
    "        config[\"mvl\"] = valid_loss\n",
    "        config[\"es\"][0] = 0\n",
    "    else: config[\"es\"][0] += 1\n",
    "    if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 85. 双方向RNN・多層化\n",
    "順方向と逆方向のRNNの両方を用いて入力テキストをエンコードし，モデルを学習せよ．\n",
    "$$\n",
    "\\overleftarrow{h}_{T+1} = 0\\\\\n",
    "\\overleftarrow{h}_t = {\\rm \\overleftarrow{RNN}}(\\mathrm{emb}(x_t), \\overleftarrow{h}_{t+1}), \\\\\n",
    "y = {\\rm softmax}(W^{(yh)} [\\overrightarrow{h}_T; \\overleftarrow{h}_1] + b^{(y)})\n",
    "$$\n",
    "<p>ただし，$\\overrightarrow{h}_t \\in \\mathbb{R}^{d_h}, \\overleftarrow{h}_t \\in \\mathbb{R}^{d_h}$はそれぞれ，順方向および逆方向のRNNで求めた時刻$t$の隠れ状態ベクトル，${\\rm \\overleftarrow{RNN}}(x,h)$は入力$x$と次時刻の隠れ状態$h$から前状態を計算するRNNユニット，$W^{(yh)} \\in \\mathbb{R}^{L \\times 2d_h}$は隠れ状態ベクトルからカテゴリを予測するための行列，$b^{(y)} \\in \\mathbb{R}^{L}$はバイアス項である．また，$[a; b]$はベクトル$a$と$b$の連結を表す。</p>\n",
    "\n",
    "<p>さらに，双方向RNNを多層化して実験せよ．</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_3(nn.Module):\n",
    "    def __init__(self, id_size, input_size, hidden_size, output_size):\n",
    "        super(Model_3, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(id_size, input_size).from_pretrained(torch.FloatTensor(vectors))\n",
    "        self.embedding.weight.requires_grad=True\n",
    "        self.rnn = RNN(input_size, hidden_size)\n",
    "        self.h2o = nn.Linear(hidden_size*2, output_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def predict(self, ids):\n",
    "        hidden_f, hidden_b = None, None\n",
    "        for i in range(ids.shape[1]):\n",
    "            x_f = self.embedding(ids[:,i])\n",
    "            x_b = self.embedding(ids[:,-i])\n",
    "            hidden_f = self.rnn(x_f,hidden_f)\n",
    "            hidden_b = self.rnn(x_b,hidden_b)\n",
    "        output = F.softmax(self.h2o(torch.cat((hidden_f,hidden_b),1)),dim=1)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, ids, y):\n",
    "        return self.loss(self.predict(ids),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es[0/20]   0 epoch train:0.1034764, valid:0.0176902, train_acc:78.298%, valid_acc:77.736%, (test_acc:79.310%)\n",
      "es[0/20]   1 epoch train:0.0996685, valid:0.0181058, train_acc:75.459%, valid_acc:74.738%, (test_acc:74.663%)\n",
      "es[1/20]   2 epoch train:0.0974259, valid:0.0185964, train_acc:72.939%, valid_acc:72.339%, (test_acc:71.364%)\n",
      "es[2/20]   3 epoch train:0.0994381, valid:0.0219204, train_acc:52.108%, valid_acc:52.324%, (test_acc:51.724%)\n",
      "es[3/20]   4 epoch train:0.0995015, valid:0.0179599, train_acc:76.649%, valid_acc:76.237%, (test_acc:76.837%)\n",
      "es[4/20]   5 epoch train:0.0979086, valid:0.0182649, train_acc:74.766%, valid_acc:73.763%, (test_acc:73.238%)\n",
      "es[5/20]   6 epoch train:0.0954595, valid:0.0183589, train_acc:76.284%, valid_acc:73.988%, (test_acc:74.288%)\n",
      "es[6/20]   7 epoch train:0.0934708, valid:0.0177361, train_acc:81.925%, valid_acc:80.660%, (test_acc:81.034%)\n",
      "es[7/20]   8 epoch train:0.0923846, valid:0.0184842, train_acc:75.600%, valid_acc:74.438%, (test_acc:73.463%)\n",
      "es[8/20]   9 epoch train:0.0922830, valid:0.0212727, train_acc:53.476%, valid_acc:53.673%, (test_acc:50.975%)\n",
      "es[9/20]  10 epoch train:0.0970944, valid:0.0244988, train_acc:51.799%, valid_acc:50.075%, (test_acc:50.750%)\n",
      "es[10/20]  11 epoch train:0.0939026, valid:0.0179002, train_acc:78.570%, valid_acc:76.162%, (test_acc:76.312%)\n",
      "es[11/20]  12 epoch train:0.0917460, valid:0.0173931, train_acc:83.265%, valid_acc:81.109%, (test_acc:80.285%)\n",
      "es[0/20]  13 epoch train:0.0901566, valid:0.0172658, train_acc:85.532%, valid_acc:83.058%, (test_acc:82.909%)\n",
      "es[0/20]  14 epoch train:0.0888775, valid:0.0177133, train_acc:83.208%, valid_acc:80.360%, (test_acc:80.585%)\n",
      "es[1/20]  15 epoch train:0.0878480, valid:0.0164899, train_acc:88.484%, valid_acc:85.907%, (test_acc:85.382%)\n",
      "es[0/20]  16 epoch train:0.0874317, valid:0.0179531, train_acc:78.027%, valid_acc:75.937%, (test_acc:74.738%)\n",
      "es[1/20]  17 epoch train:0.0877329, valid:0.0173272, train_acc:86.207%, valid_acc:83.733%, (test_acc:83.658%)\n",
      "es[2/20]  18 epoch train:0.0866938, valid:0.0179573, train_acc:81.034%, valid_acc:79.085%, (test_acc:76.387%)\n",
      "es[3/20]  19 epoch train:0.0847362, valid:0.0173282, train_acc:91.098%, valid_acc:87.556%, (test_acc:87.106%)\n",
      "es[4/20]  20 epoch train:0.0846855, valid:0.0174286, train_acc:89.889%, valid_acc:85.682%, (test_acc:86.507%)\n",
      "es[5/20]  21 epoch train:0.0854799, valid:0.0168248, train_acc:88.493%, valid_acc:83.958%, (test_acc:83.208%)\n",
      "es[6/20]  22 epoch train:0.0836399, valid:0.0166146, train_acc:88.728%, valid_acc:85.382%, (test_acc:85.382%)\n",
      "es[7/20]  23 epoch train:0.0843676, valid:0.0162839, train_acc:93.310%, valid_acc:88.981%, (test_acc:87.481%)\n",
      "es[0/20]  24 epoch train:0.0829104, valid:0.0162458, train_acc:92.635%, valid_acc:88.381%, (test_acc:87.706%)\n",
      "es[0/20]  25 epoch train:0.0825122, valid:0.0164636, train_acc:93.272%, valid_acc:89.430%, (test_acc:88.681%)\n",
      "es[1/20]  26 epoch train:0.0830789, valid:0.0177034, train_acc:82.468%, valid_acc:78.036%, (test_acc:77.661%)\n",
      "es[2/20]  27 epoch train:0.0839693, valid:0.0166203, train_acc:91.689%, valid_acc:87.181%, (test_acc:86.582%)\n",
      "es[3/20]  28 epoch train:0.0826164, valid:0.0160251, train_acc:93.872%, valid_acc:89.205%, (test_acc:89.280%)\n",
      "es[0/20]  29 epoch train:0.0831520, valid:0.0164057, train_acc:93.909%, valid_acc:88.456%, (test_acc:87.181%)\n",
      "es[1/20]  30 epoch train:0.0831219, valid:0.0169796, train_acc:88.362%, valid_acc:84.033%, (test_acc:83.358%)\n",
      "es[2/20]  31 epoch train:0.0824386, valid:0.0167789, train_acc:93.403%, valid_acc:88.831%, (test_acc:87.931%)\n",
      "es[3/20]  32 epoch train:0.0825528, valid:0.0163573, train_acc:91.164%, valid_acc:87.256%, (test_acc:84.183%)\n",
      "es[4/20]  33 epoch train:0.0829017, valid:0.0168561, train_acc:93.619%, valid_acc:88.531%, (test_acc:88.006%)\n",
      "es[5/20]  34 epoch train:0.0822315, valid:0.0166772, train_acc:93.956%, valid_acc:89.580%, (test_acc:88.606%)\n",
      "es[6/20]  35 epoch train:0.0810656, valid:0.0178964, train_acc:86.975%, valid_acc:82.309%, (test_acc:82.459%)\n",
      "es[7/20]  36 epoch train:0.0822091, valid:0.0166885, train_acc:90.920%, valid_acc:86.582%, (test_acc:85.982%)\n",
      "es[8/20]  37 epoch train:0.0831789, valid:0.0164904, train_acc:90.536%, valid_acc:86.132%, (test_acc:85.757%)\n",
      "es[9/20]  38 epoch train:0.0816234, valid:0.0168052, train_acc:93.816%, valid_acc:87.931%, (test_acc:86.432%)\n",
      "es[10/20]  39 epoch train:0.0809730, valid:0.0165064, train_acc:94.078%, valid_acc:88.906%, (test_acc:88.381%)\n",
      "es[11/20]  40 epoch train:0.0817900, valid:0.0170893, train_acc:91.033%, valid_acc:87.181%, (test_acc:86.357%)\n",
      "es[12/20]  41 epoch train:0.0830410, valid:0.0165404, train_acc:89.655%, valid_acc:85.457%, (test_acc:85.007%)\n",
      "es[13/20]  42 epoch train:0.0822662, valid:0.0180004, train_acc:84.914%, valid_acc:80.735%, (test_acc:77.511%)\n",
      "es[14/20]  43 epoch train:0.0809941, valid:0.0166026, train_acc:95.071%, valid_acc:90.330%, (test_acc:87.481%)\n",
      "es[15/20]  44 epoch train:0.0809851, valid:0.0178315, train_acc:91.079%, valid_acc:85.232%, (test_acc:84.108%)\n",
      "es[16/20]  45 epoch train:0.0855801, valid:0.0180661, train_acc:80.772%, valid_acc:77.661%, (test_acc:74.813%)\n",
      "es[17/20]  46 epoch train:0.0839503, valid:0.0166181, train_acc:91.642%, valid_acc:86.207%, (test_acc:84.858%)\n",
      "es[18/20]  47 epoch train:0.0824978, valid:0.0171024, train_acc:91.904%, valid_acc:86.882%, (test_acc:85.307%)\n",
      "es[19/20]  48 epoch train:0.0836097, valid:0.0171315, train_acc:90.058%, valid_acc:84.708%, (test_acc:84.258%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = Model_3(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train(model,optimizer,batch_size=10,shuffle=True,config={\"epoch\":epoch},device='cuda')\n",
    "    valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device='cuda')\n",
    "    print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "    if valid_loss < config[\"mvl\"]: \n",
    "        config[\"mvl\"] = valid_loss\n",
    "        config[\"es\"][0] = 0\n",
    "    else: config[\"es\"][0] += 1\n",
    "    if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 86. 畳み込みニューラルネットワーク (CNN)\n",
    "<p>ID番号で表現された単語列$\\boldsymbol{x} = (x_1, x_2, \\dots, x_T)$がある．ただし，$T$は単語列の長さ，$x_t \\in \\mathbb{R}^{V}$は単語のID番号のone-hot表記である（$V$は単語の総数である）．畳み込みニューラルネットワーク（CNN: Convolutional Neural Network）を用い，単語列$\\boldsymbol{x}$からカテゴリ$y$を予測するモデルを実装せよ．ただし，畳み込みニューラルネットワークの構成は以下の通りとする．</p>\n",
    "<ul>\n",
    "  <li>単語埋め込みの次元数: $d_w$</li>\n",
    "  <li>畳み込みのフィルターのサイズ: 3 トークン</li>\n",
    "  <li>畳み込みのストライド: 1 トークン</li>\n",
    "  <li>畳み込みのパディング: あり</li>\n",
    "  <li>畳み込み演算後の各時刻のベクトルの次元数: $d_h$</li>\n",
    "  <li>畳み込み演算後に最大値プーリング（max pooling）を適用し，入力文を$d_h$次元の隠れベクトルで表現</li>\n",
    "</ul>\n",
    "<p>すなわち，時刻$t$の特徴ベクトル$p_t \\in \\mathbb{R}^{d_h}$は次式で表される．$p_t = g(W^{(px)} [\\mathrm{emb}(x_{t-1}); \\mathrm{emb}(x_t); \\mathrm{emb}(x_{t+1})] + b^{(p)})$</p> \n",
    "<p>ただし，$W^{(px)} \\in \\mathbb{R}^{d_h \\times 3d_w}, b^{(p)} \\in \\mathbb{R}^{d_h}$はCNNのパラメータ，$g$は活性化関数（例えば$\\tanh$やReLUなど），$[a; b; c]$はベクトル$a, b, c$の連結である．なお，行列$W^{(px)}$の列数が$3d_w$になるのは，3個のトークンの単語埋め込みを連結したものに対して，線形変換を行うためである．</p>\n",
    "<p>最大値プーリングでは，特徴ベクトルの次元毎に全時刻における最大値を取り，入力文書の特徴ベクトル$c \\in \\mathbb{R}^{d_h}$を求める．$c[i]$でベクトル$c$の$i$番目の次元の値を表すことにすると，最大値プーリングは$c[i] = \\max_{1 \\leq t \\leq T} p_t[i]$で表される．</p> \n",
    "<p>最後に，入力文書の特徴ベクトル$c$に行列$W^{(yc)} \\in \\mathbb{R}^{L \\times d_h}$とバイアス項$b^{(y)} \\in \\mathbb{R}^{L}$による線形変換とソフトマックス関数を適用し，カテゴリ$y$を予測する．$y = {\\rm softmax}(W^{(yc)} c + b^{(y)})$</p>\n",
    "<p>なお，この問題ではモデルの学習を行わず，ランダムに初期化された重み行列で$y$を計算するだけでよい．</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_4(nn.Module):\n",
    "    def __init__(self, id_size, input_size, hidden_size, output_size):\n",
    "        super(Model_4, self).__init__()\n",
    "        self.embedding = nn.Embedding(id_size, input_size)\n",
    "        self.conv = nn.Conv1d(input_size, hidden_size, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=3)\n",
    "        self.h2o = nn.Linear(hidden_size, output_size)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def predict(self, ids):\n",
    "        embs = self.embedding(ids).permute(0,2,1)\n",
    "        x = torch.max_pool1d(self.conv(embs),kernel_size=ids.shape[1])[:,:,0]\n",
    "        output = F.softmax(self.h2o(x),dim=1)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, ids, y):\n",
    "        return self.loss(self.predict(ids),y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"87-確率的勾配降下法によるcnnの学習\">87. 確率的勾配降下法によるCNNの学習</h2>\n",
    "\n",
    "<p>確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，問題86で構築したモデルを学習せよ．訓練データ上の損失と正解率，評価データ上の損失と正解率を表示しながらモデルを学習し，適当な基準（例えば10エポックなど）で終了させよ．</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es[0/20]   0 epoch train:0.1056864, valid:0.0189556, train_acc:74.560%, valid_acc:71.814%, (test_acc:72.039%)\n",
      "es[0/20]   1 epoch train:0.0995063, valid:0.0187900, train_acc:77.240%, valid_acc:74.213%, (test_acc:73.613%)\n",
      "es[0/20]   2 epoch train:0.0972003, valid:0.0189767, train_acc:77.183%, valid_acc:72.714%, (test_acc:71.289%)\n",
      "es[1/20]   3 epoch train:0.0962148, valid:0.0192758, train_acc:75.637%, valid_acc:70.465%, (test_acc:69.490%)\n",
      "es[2/20]   4 epoch train:0.0955914, valid:0.0187541, train_acc:79.423%, valid_acc:75.262%, (test_acc:74.438%)\n",
      "es[0/20]   5 epoch train:0.0951855, valid:0.0185506, train_acc:80.107%, valid_acc:75.337%, (test_acc:74.588%)\n",
      "es[0/20]   6 epoch train:0.0948735, valid:0.0185863, train_acc:80.266%, valid_acc:75.412%, (test_acc:74.588%)\n",
      "es[1/20]   7 epoch train:0.0944737, valid:0.0183168, train_acc:80.885%, valid_acc:76.762%, (test_acc:76.462%)\n",
      "es[0/20]   8 epoch train:0.0942941, valid:0.0183376, train_acc:80.997%, valid_acc:76.687%, (test_acc:75.037%)\n",
      "es[1/20]   9 epoch train:0.0942425, valid:0.0183745, train_acc:81.063%, valid_acc:76.237%, (test_acc:76.462%)\n",
      "es[2/20]  10 epoch train:0.0941070, valid:0.0183883, train_acc:81.100%, valid_acc:76.087%, (test_acc:76.087%)\n",
      "es[3/20]  11 epoch train:0.0940501, valid:0.0184921, train_acc:81.119%, valid_acc:75.862%, (test_acc:75.637%)\n",
      "es[4/20]  12 epoch train:0.0933821, valid:0.0188542, train_acc:81.269%, valid_acc:72.939%, (test_acc:69.790%)\n",
      "es[5/20]  13 epoch train:0.0915046, valid:0.0179872, train_acc:84.267%, valid_acc:78.861%, (test_acc:76.537%)\n",
      "es[0/20]  14 epoch train:0.0897078, valid:0.0181560, train_acc:84.033%, valid_acc:77.586%, (test_acc:75.337%)\n",
      "es[1/20]  15 epoch train:0.0883575, valid:0.0181012, train_acc:87.687%, valid_acc:78.036%, (test_acc:76.387%)\n",
      "es[2/20]  16 epoch train:0.0872205, valid:0.0181434, train_acc:86.713%, valid_acc:78.036%, (test_acc:76.237%)\n",
      "es[3/20]  17 epoch train:0.0862577, valid:0.0180727, train_acc:89.496%, valid_acc:79.085%, (test_acc:78.636%)\n",
      "es[4/20]  18 epoch train:0.0858201, valid:0.0179407, train_acc:89.571%, valid_acc:79.610%, (test_acc:78.786%)\n",
      "es[0/20]  19 epoch train:0.0853927, valid:0.0183897, train_acc:90.386%, valid_acc:79.760%, (test_acc:77.511%)\n",
      "es[1/20]  20 epoch train:0.0848821, valid:0.0185651, train_acc:90.733%, valid_acc:79.910%, (test_acc:77.811%)\n",
      "es[2/20]  21 epoch train:0.0844681, valid:0.0184507, train_acc:89.721%, valid_acc:78.036%, (test_acc:77.136%)\n",
      "es[3/20]  22 epoch train:0.0838425, valid:0.0190251, train_acc:89.721%, valid_acc:73.838%, (test_acc:72.864%)\n",
      "es[4/20]  23 epoch train:0.0830279, valid:0.0181972, train_acc:93.431%, valid_acc:78.936%, (test_acc:77.586%)\n",
      "es[5/20]  24 epoch train:0.0824363, valid:0.0180887, train_acc:93.300%, valid_acc:78.186%, (test_acc:77.061%)\n",
      "es[6/20]  25 epoch train:0.0812203, valid:0.0169714, train_acc:95.071%, valid_acc:81.859%, (test_acc:79.160%)\n",
      "es[0/20]  26 epoch train:0.0807137, valid:0.0184677, train_acc:93.628%, valid_acc:76.462%, (test_acc:76.312%)\n",
      "es[1/20]  27 epoch train:0.0831740, valid:0.0179335, train_acc:93.956%, valid_acc:79.835%, (test_acc:77.736%)\n",
      "es[2/20]  28 epoch train:0.0811850, valid:0.0176018, train_acc:95.437%, valid_acc:81.409%, (test_acc:79.235%)\n",
      "es[3/20]  29 epoch train:0.0802702, valid:0.0176533, train_acc:95.746%, valid_acc:81.334%, (test_acc:80.510%)\n",
      "es[4/20]  30 epoch train:0.0796297, valid:0.0176500, train_acc:95.849%, valid_acc:81.634%, (test_acc:79.085%)\n",
      "es[5/20]  31 epoch train:0.0795194, valid:0.0179619, train_acc:95.624%, valid_acc:79.160%, (test_acc:79.235%)\n",
      "es[6/20]  32 epoch train:0.0791182, valid:0.0176788, train_acc:96.636%, valid_acc:82.234%, (test_acc:80.885%)\n",
      "es[7/20]  33 epoch train:0.0788327, valid:0.0177775, train_acc:96.608%, valid_acc:81.559%, (test_acc:80.810%)\n",
      "es[8/20]  34 epoch train:0.0787107, valid:0.0176743, train_acc:96.749%, valid_acc:82.534%, (test_acc:81.034%)\n",
      "es[9/20]  35 epoch train:0.0784854, valid:0.0171386, train_acc:96.898%, valid_acc:83.433%, (test_acc:81.784%)\n",
      "es[10/20]  36 epoch train:0.0783637, valid:0.0177183, train_acc:96.645%, valid_acc:81.709%, (test_acc:80.585%)\n",
      "es[11/20]  37 epoch train:0.0783120, valid:0.0174619, train_acc:96.992%, valid_acc:83.208%, (test_acc:81.034%)\n",
      "es[12/20]  38 epoch train:0.0782474, valid:0.0174804, train_acc:97.076%, valid_acc:83.283%, (test_acc:81.334%)\n",
      "es[13/20]  39 epoch train:0.0782450, valid:0.0174244, train_acc:97.095%, valid_acc:83.133%, (test_acc:81.184%)\n",
      "es[14/20]  40 epoch train:0.0781600, valid:0.0174094, train_acc:97.142%, valid_acc:83.358%, (test_acc:81.034%)\n",
      "es[15/20]  41 epoch train:0.0781308, valid:0.0174083, train_acc:97.142%, valid_acc:83.133%, (test_acc:80.960%)\n",
      "es[16/20]  42 epoch train:0.0781251, valid:0.0174271, train_acc:97.142%, valid_acc:83.133%, (test_acc:81.109%)\n",
      "es[17/20]  43 epoch train:0.0781572, valid:0.0174054, train_acc:97.151%, valid_acc:83.208%, (test_acc:81.259%)\n",
      "es[18/20]  44 epoch train:0.0781276, valid:0.0174444, train_acc:97.151%, valid_acc:83.133%, (test_acc:81.109%)\n",
      "es[19/20]  45 epoch train:0.0781365, valid:0.0174309, train_acc:97.151%, valid_acc:83.133%, (test_acc:81.109%)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = Model_4(id_size=id_size,input_size=300,hidden_size=50,output_size=4)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = train(model,optimizer,batch_size=10,shuffle=True,config={\"epoch\":epoch},device='cuda')\n",
    "    valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device='cuda')\n",
    "    print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "    if valid_loss < config[\"mvl\"]: \n",
    "        config[\"mvl\"] = valid_loss\n",
    "        config[\"es\"][0] = 0\n",
    "    else: config[\"es\"][0] += 1\n",
    "    if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 88. パラメータチューニング\n",
    "<p>問題85や問題87のコードを改変し，ニューラルネットワークの形状やハイパーパラメータを調整しながら，高性能なカテゴリ分類器を構築せよ．</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 10\n",
      "es[0/20]   0 epoch train:0.1071648, valid:0.0197895, train_acc:67.391%, valid_acc:65.742%, (test_acc:65.367%)                                                                                           \n",
      "es[0/20]   1 epoch train:0.1018732, valid:0.0192253, train_acc:73.829%, valid_acc:71.589%, (test_acc:69.640%)                                                                                           \n",
      "es[0/20]   2 epoch train:0.0997379, valid:0.0188779, train_acc:75.159%, valid_acc:72.564%, (test_acc:70.915%)                                                                                           \n",
      "es[0/20]   6 epoch train:0.0963806, valid:0.0186726, train_acc:78.748%, valid_acc:73.763%, (test_acc:74.288%)                                                                                           \n",
      "es[0/20]  11 epoch train:0.0923391, valid:0.0186568, train_acc:82.534%, valid_acc:76.312%, (test_acc:73.538%)                                                                                           \n",
      "es[0/20]  13 epoch train:0.0917379, valid:0.0184654, train_acc:83.939%, valid_acc:76.237%, (test_acc:73.838%)                                                                                           \n",
      "es[0/20]  21 epoch train:0.0901362, valid:0.0184416, train_acc:85.542%, valid_acc:76.537%, (test_acc:73.688%)                                                                                           \n",
      "es[0/20]  29 epoch train:0.0884696, valid:0.0180491, train_acc:87.322%, valid_acc:76.387%, (test_acc:75.637%)                                                                                           \n",
      "es[0/20]  35 epoch train:0.0876819, valid:0.0179033, train_acc:87.631%, valid_acc:76.162%, (test_acc:75.712%)                                                                                           \n",
      "es[0/20]  37 epoch train:0.0875410, valid:0.0176182, train_acc:87.734%, valid_acc:76.837%, (test_acc:76.612%)                                                                                           \n",
      "es[0/20]  40 epoch train:0.0871546, valid:0.0174167, train_acc:88.315%, valid_acc:77.061%, (test_acc:76.912%)                                                                                           \n",
      "hidden_size: 50poch train:0.0868752, valid:0.0175065, train_acc:88.118%, valid_acc:76.462%, (test_acc:75.412%)                                                                                          \n",
      "es[0/20]   0 epoch train:0.1054880, valid:0.0200672, train_acc:71.083%, valid_acc:69.115%, (test_acc:68.666%)                                                                                           \n",
      "es[0/20]   1 epoch train:0.0994600, valid:0.0195373, train_acc:75.881%, valid_acc:72.339%, (test_acc:71.589%)                                                                                           \n",
      "es[0/20]   2 epoch train:0.0969753, valid:0.0189308, train_acc:76.743%, valid_acc:71.514%, (test_acc:71.064%)                                                                                           \n",
      "es[0/20]   3 epoch train:0.0957461, valid:0.0188076, train_acc:79.226%, valid_acc:73.613%, (test_acc:74.063%)                                                                                           \n",
      "es[0/20]   4 epoch train:0.0951269, valid:0.0187188, train_acc:80.266%, valid_acc:74.813%, (test_acc:74.963%)                                                                                           \n",
      "es[0/20]  10 epoch train:0.0939663, valid:0.0186405, train_acc:81.297%, valid_acc:75.712%, (test_acc:75.112%)                                                                                           \n",
      "es[0/20]  13 epoch train:0.0917680, valid:0.0186200, train_acc:82.393%, valid_acc:75.487%, (test_acc:75.412%)                                                                                           \n",
      "es[0/20]  14 epoch train:0.0896231, valid:0.0183259, train_acc:86.910%, valid_acc:77.661%, (test_acc:77.061%)                                                                                           \n",
      "es[0/20]  16 epoch train:0.0864535, valid:0.0179402, train_acc:90.152%, valid_acc:78.411%, (test_acc:78.411%)                                                                                           \n",
      "es[0/20]  23 epoch train:0.0794551, valid:0.0178642, train_acc:95.690%, valid_acc:80.135%, (test_acc:77.961%)                                                                                           \n",
      "es[0/20]  24 epoch train:0.0791160, valid:0.0176693, train_acc:96.168%, valid_acc:81.034%, (test_acc:78.561%)                                                                                           \n",
      "es[0/20]  28 epoch train:0.0783536, valid:0.0175900, train_acc:97.133%, valid_acc:81.109%, (test_acc:79.910%)                                                                                           \n",
      "hidden_size: 100och train:0.0778734, valid:0.0177444, train_acc:97.498%, valid_acc:80.735%, (test_acc:80.210%)                                                                                          \n",
      "es[0/20]   0 epoch train:0.1051544, valid:0.0192401, train_acc:75.825%, valid_acc:72.714%, (test_acc:73.313%)                                                                                           \n",
      "es[0/20]   1 epoch train:0.0995013, valid:0.0188202, train_acc:76.771%, valid_acc:72.864%, (test_acc:72.864%)                                                                                           \n",
      "es[0/20]   3 epoch train:0.0956782, valid:0.0186578, train_acc:78.373%, valid_acc:73.163%, (test_acc:73.163%)                                                                                           \n",
      "es[0/20]   5 epoch train:0.0945827, valid:0.0181778, train_acc:80.894%, valid_acc:75.712%, (test_acc:75.937%)                                                                                           \n",
      "es[0/20]   6 epoch train:0.0941426, valid:0.0180258, train_acc:81.072%, valid_acc:76.087%, (test_acc:76.387%)                                                                                           \n",
      "es[0/20]  19 epoch train:0.0814467, valid:0.0178315, train_acc:95.558%, valid_acc:81.859%, (test_acc:80.885%))                                                                                          \n",
      "es[0/20]  22 epoch train:0.0790041, valid:0.0175049, train_acc:95.905%, valid_acc:80.660%, (test_acc:80.135%)                                                                                           \n",
      "es[0/20]  24 epoch train:0.0787196, valid:0.0171001, train_acc:96.973%, valid_acc:83.133%, (test_acc:81.109%)                                                                                           \n",
      "es[0/20]  26 epoch train:0.0781117, valid:0.0170022, train_acc:97.292%, valid_acc:83.583%, (test_acc:80.360%)                                                                                           \n",
      "es[0/20]  27 epoch train:0.0780215, valid:0.0169185, train_acc:97.367%, valid_acc:83.433%, (test_acc:80.960%)                                                                                           \n",
      "es[0/20]  42 epoch train:0.0777287, valid:0.0169121, train_acc:97.386%, valid_acc:83.583%, (test_acc:80.360%))                                                                                          \n",
      "hidden_size: 200och train:0.0775495, valid:0.0171671, train_acc:97.732%, valid_acc:83.133%, (test_acc:80.585%)                                                                                          \n",
      "es[0/20]   0 epoch train:0.1075786, valid:0.0203986, train_acc:68.216%, valid_acc:65.292%, (test_acc:66.867%)                                                                                           \n",
      "es[0/20]   1 epoch train:0.1001483, valid:0.0188210, train_acc:77.015%, valid_acc:73.088%, (test_acc:72.339%)                                                                                           \n",
      "es[0/20]   2 epoch train:0.0972362, valid:0.0182452, train_acc:79.001%, valid_acc:74.963%, (test_acc:75.187%)                                                                                           \n",
      "es[0/20]   8 epoch train:0.0920865, valid:0.0177793, train_acc:83.630%, valid_acc:76.837%, (test_acc:76.687%)                                                                                           \n",
      "es[0/20]  15 epoch train:0.0799778, valid:0.0177449, train_acc:92.429%, valid_acc:78.561%, (test_acc:78.336%)                                                                                           \n",
      "es[0/20]  18 epoch train:0.0782467, valid:0.0169208, train_acc:97.433%, valid_acc:81.709%, (test_acc:82.009%)                                                                                           \n",
      "es[0/20]  21 epoch train:0.0775573, valid:0.0167669, train_acc:97.910%, valid_acc:83.133%, (test_acc:83.358%)                                                                                           \n",
      "hidden_size: 300och train:0.0770802, valid:0.0175758, train_acc:98.220%, valid_acc:82.309%, (test_acc:82.609%)                                                                                          \n",
      "es[0/20]   0 epoch train:0.1338387, valid:0.0261119, train_acc:42.101%, valid_acc:40.930%, (test_acc:44.078%)                                                                                           \n",
      "es[0/20]   1 epoch train:0.1340661, valid:0.0261104, train_acc:42.101%, valid_acc:40.930%, (test_acc:44.078%)                                                                                           \n",
      "es[0/20]   2 epoch train:0.1082533, valid:0.0191269, train_acc:72.067%, valid_acc:70.090%, (test_acc:68.066%)                                                                                           \n",
      "es[0/20]   4 epoch train:0.0966380, valid:0.0186710, train_acc:79.901%, valid_acc:76.612%, (test_acc:74.738%)                                                                                           \n",
      "es[0/20]   7 epoch train:0.0942999, valid:0.0184299, train_acc:80.978%, valid_acc:76.237%, (test_acc:76.387%)                                                                                           \n",
      "es[0/20]  10 epoch train:0.0937220, valid:0.0183757, train_acc:81.269%, valid_acc:76.987%, (test_acc:76.537%)                                                                                           \n",
      "es[0/20]  11 epoch train:0.0938461, valid:0.0182557, train_acc:81.344%, valid_acc:77.586%, (test_acc:76.012%)                                                                                           \n",
      "es[0/20]  16 epoch train:0.0852217, valid:0.0175271, train_acc:90.480%, valid_acc:81.934%, (test_acc:78.111%)                                                                                           \n",
      "es[19/20]  36 epoch train:0.0768567, valid:0.0180341, train_acc:98.435%, valid_acc:82.909%, (test_acc:82.759%)                                                                                          \r"
     ]
    }
   ],
   "source": [
    "for hidden_size in [10,50,100,200,300]:\n",
    "    print(f\"hidden_size: {hidden_size}\")\n",
    "    model = Model_4(id_size=id_size,input_size=300,hidden_size=hidden_size,output_size=4)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    config = {\"es\":[0,20], \"mvl\":10000.} # early_stopping, min_val_loss\n",
    "    for epoch in range(100):\n",
    "        train_loss = train(model,optimizer,batch_size=10,shuffle=True,config={\"epoch\":epoch},device='cuda')\n",
    "        valid_loss = evaluate(model,\"valid\",batch_size=100,config={\"epoch\":epoch},device='cuda')\n",
    "        print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100,end=\"\\r\")\n",
    "        if valid_loss < config[\"mvl\"]: \n",
    "            config[\"mvl\"] = valid_loss\n",
    "            config[\"es\"][0] = 0\n",
    "            print_state(config[\"es\"],epoch,train_loss,valid_loss,accuracy(model,\"train\")*100,accuracy(model,\"valid\")*100,accuracy(model,\"test\")*100)\n",
    "        else: config[\"es\"][0] += 1\n",
    "        if config[\"es\"][0] >= config[\"es\"][1]: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 89. 事前学習済み言語モデルからの転移学習\n",
    "<p>事前学習済み言語モデル（例えば<a href=\"https://github.com/google-research/bert\">BERT</a>など）を出発点として，ニュース記事見出しをカテゴリに分類するモデルを構築せよ．</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[bert-for-tf2](https://pypi.org/project/bert-for-tf2/)を使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/google-research/bert#bert からパラメータをDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for mode in [\"train\",\"test\",\"valid\"]:\n",
    "    exec(f\"{mode}_X = []\")\n",
    "    with open(f'{mode}_X.feature.txt') as f:\n",
    "        for line in f: exec(f\"{mode}_X.append(line.rstrip())\")\n",
    "    exec(f\"{mode}_Y = []\")\n",
    "    with open(f'{mode}_Y.txt') as f:\n",
    "        for line in f: exec(f\"{mode}_Y.append((int)(line.rstrip()))\")\n",
    "        exec(f\"{mode}_Y = np.array({mode}_Y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"uncased_L-2_H-128_A-2\"  # tiny\n",
    "model_name = \"uncased_L-4_H-256_A-4\"  # mini\n",
    "# model_name = \"uncased_L-4_H-512_A-8\"  # small\n",
    "# model_name = \"uncased_L-8_H-512_A-8\"  # midium\n",
    "# model_name = \"uncased_L-12_H-768_A-12\" # base\n",
    "\n",
    "model_name_zip = model_name+\".zip\"\n",
    "model_dir = \"models/\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models/$model_name_zip > /dev/null 2>&1 || wget -q -P models/ https://storage.googleapis.com/bert_models/2020_02_20/$model_name_zip\n",
    "!ls models/$model_name > /dev/null 2>&1 || unzip models/$model_name_zip -d models/$model_name/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, bert\n",
    "import tensorflow as tf\n",
    "do_lower_case = not (model_name.find(\"cased\") == 0 or model_name.find(\"multi_cased\") == 0)\n",
    "model_ckpt = os.path.join(model_dir, \"bert_model.ckpt\")\n",
    "bert.bert_tokenization.validate_case_matches_checkpoint(do_lower_case, model_ckpt)\n",
    "vocab_file = os.path.join(model_dir, \"vocab.txt\")\n",
    "tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_len = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4bert = {}\n",
    "for mode in [\"train\",\"test\",\"valid\"]:\n",
    "    data4bert[mode] = {}\n",
    "    data4bert[mode][\"X\"] = []\n",
    "    for elm in eval(f\"{mode}_X\"):\n",
    "        ids = tokenizer.tokenize(elm)\n",
    "        ids = [\"[CLS]\"] + ids\n",
    "        if len(ids) <= max_seq_len: ids.extend([\"[PAD]\"]*(max_seq_len-len(ids)))\n",
    "        else: ids = ids[:max_seq_len]\n",
    "        ids = tokenizer.convert_tokens_to_ids(ids)\n",
    "        data4bert[mode][\"X\"].append(np.asarray(ids))\n",
    "    data4bert[mode][\"X\"] = tf.convert_to_tensor(np.asarray(data4bert[mode][\"X\"]),np.int32)\n",
    "    data4bert[mode][\"Y\"] = [[int(i==elm) for i in range(4)] for elm in eval(f\"{mode}_Y\")]\n",
    "    data4bert[mode][\"Y\"] = tf.convert_to_tensor(np.asarray(data4bert[mode][\"Y\"]),np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "bert_params = bert.params_from_pretrained_ckpt(model_dir)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=(max_seq_len,), dtype='int32'))\n",
    "model.add(bert.BertModelLayer.from_params(bert_params))\n",
    "model.add(keras.layers.Lambda(lambda x:x[:,0,:]))\n",
    "model.add(keras.layers.Dense(4,activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bert_model_layer (BertModelL (None, 42, 256)           11104256  \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 11,105,284\n",
      "Trainable params: 11,105,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "214/214 [==============================] - 42s 194ms/step - loss: 0.7172 - accuracy: 0.7813 - val_loss: 0.3097 - val_accuracy: 0.8876\n",
      "Epoch 2/1000\n",
      "214/214 [==============================] - 41s 192ms/step - loss: 0.1949 - accuracy: 0.9395 - val_loss: 0.2640 - val_accuracy: 0.9123\n",
      "Epoch 3/1000\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.0966 - accuracy: 0.9682 - val_loss: 0.5277 - val_accuracy: 0.8673\n",
      "Epoch 4/1000\n",
      "214/214 [==============================] - 39s 185ms/step - loss: 0.3876 - accuracy: 0.8682 - val_loss: 0.8466 - val_accuracy: 0.7541\n",
      "Epoch 5/1000\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.6270 - accuracy: 0.7861 - val_loss: 0.6330 - val_accuracy: 0.7939\n",
      "Epoch 6/1000\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.5173 - accuracy: 0.8232 - val_loss: 0.6531 - val_accuracy: 0.7751\n",
      "Epoch 7/1000\n",
      "214/214 [==============================] - 40s 185ms/step - loss: 0.7721 - accuracy: 0.7269 - val_loss: 0.9939 - val_accuracy: 0.6289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9718648580>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data4bert[\"train\"][\"X\"],data4bert[\"train\"][\"Y\"], \n",
    "          batch_size=50,\n",
    "          epochs=1000,\n",
    "          shuffle=True, \n",
    "          validation_data=(data4bert[\"valid\"][\"X\"],data4bert[\"valid\"][\"Y\"]),\n",
    "          callbacks=[\n",
    "              keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "              keras.callbacks.TensorBoard(log_dir='./logs', profile_batch=5),\n",
    "              keras.callbacks.ModelCheckpoint(filepath = 'save.h5', monitor='val_loss', save_best_only=True, save_weights_only=False)\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 1s 29ms/step - loss: 0.2640 - accuracy: 0.9153\n",
      "loss: 0.2639651894569397, accuracy: 0.9152923822402954\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('save.h5')\n",
    "score = model.evaluate(data4bert[\"test\"][\"X\"],data4bert[\"test\"][\"Y\"])\n",
    "print(\"loss: {}, accuracy: {}\".format(score[0],score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9422681e-01, 4.4401856e-03, 6.7161687e-04, 6.6137780e-04],\n",
       "       [2.1671921e-03, 6.9982465e-04, 9.9568838e-01, 1.4445955e-03],\n",
       "       [9.6995831e-01, 2.8018415e-02, 9.3047682e-04, 1.0928334e-03],\n",
       "       [3.7689975e-03, 2.2537501e-03, 9.9307632e-01, 9.0092456e-04],\n",
       "       [8.6668396e-01, 6.7405105e-02, 5.2539423e-02, 1.3371416e-02],\n",
       "       [9.8821111e-03, 1.1280120e-02, 9.7520530e-01, 3.6324922e-03],\n",
       "       [4.5831839e-04, 2.1671398e-04, 9.9666142e-01, 2.6635372e-03],\n",
       "       [9.8911893e-01, 9.9838888e-03, 5.4392463e-04, 3.5325595e-04],\n",
       "       [9.8868179e-01, 9.0399981e-03, 1.4054673e-03, 8.7280519e-04],\n",
       "       [9.8485804e-01, 1.3786187e-02, 8.9826446e-04, 4.5749312e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data4bert[\"train\"][\"X\"][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
